{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0dec8a5ff48d192d3613b9e6713a72fe103c8e5d5c44dc7b8ee41f3376e4a4f37",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## ResNet 실험\n",
    "### 과연 Gradient가 얼마나 유지되는걸까? \n",
    "### 진짜 Gradient Vanishing이 일어날까?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import cv2\n",
    "import xmltodict\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from glob import glob"
   ]
  },
  {
   "source": [
    "## 데이터셋 휙득"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_path = '/home/ubuntu/CUAI_2021/Advanced_Minkyu_Kim/PASCAL_VOC_2007/train/VOCdevkit/VOC2007/JPEGImages'\n",
    "train_y_path = '/home/ubuntu/CUAI_2021/Advanced_Minkyu_Kim/PASCAL_VOC_2007/train/VOCdevkit/VOC2007/Annotations'\n",
    "\n",
    "# 파일 경로 휙득\n",
    "list_train_x = sorted([x for x in glob(train_x_path + '/**')])    \n",
    "list_train_y = sorted([x for x in glob(train_y_path + '/**')]) \n",
    "\n",
    "image_file_list = sorted([x for x in glob(train_x_path + '/**')])\n",
    "xml_file_list = sorted([x for x in glob(train_y_path + '/**')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋에 존재하는 클래스가 얼마나 있는지 알아낸다\n",
    "def get_Classes_inImage(xml_file_list):\n",
    "    Classes_inDataSet = []\n",
    "\n",
    "    for xml_file_path in xml_file_list: \n",
    "\n",
    "        f = open(xml_file_path)\n",
    "        xml_file = xmltodict.parse(f.read())\n",
    "        # 사진에 객체가 여러개 있을 경우\n",
    "        try: \n",
    "            for obj in xml_file['annotation']['object']:\n",
    "                Classes_inDataSet.append(obj['name'].lower()) # 들어있는 객체 종류를 알아낸다\n",
    "        # 사진에 객체가 하나만 있을 경우\n",
    "        except TypeError as e: \n",
    "            Classes_inDataSet.append(xml_file['annotation']['object']['name'].lower()) \n",
    "        f.close()\n",
    "\n",
    "    Classes_inDataSet = list(set(Classes_inDataSet)) # set은 중복된걸 다 제거하고 유니크한? 아무튼 하나만 가져온다. 그걸 리스트로 만든다\n",
    "    Classes_inDataSet.sort() # 정렬\n",
    "\n",
    "    return Classes_inDataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 객체 하나만 있는 이미지 사진만 데이터셋으로 쓴다.\n",
    "def make_dataSet_onlyOneClassImage(xml_file_list, image_file_list, Classes_inDataSet):\n",
    "\n",
    "    # 데이터셋\n",
    "    images_list = []\n",
    "    Class_Label_list = []\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    for xml_file_path in xml_file_list: \n",
    "\n",
    "        Classes_inDataSet = []\n",
    "\n",
    "        f = open(xml_file_path)\n",
    "        xml_file = xmltodict.parse(f.read())\n",
    "        # 사진에 객체가 여러개 있을 경우\n",
    "        try: \n",
    "            for obj in xml_file['annotation']['object']:\n",
    "                Classes_inDataSet.append(obj['name'].lower()) # 들어있는 객체 종류를 알아낸다\n",
    "        # 사진에 객체가 하나만 있을 경우\n",
    "        except TypeError as e: \n",
    "            Classes_inDataSet.append(xml_file['annotation']['object']['name'].lower()) \n",
    "        f.close()\n",
    "\n",
    "        # 객체가 하나만 있는 데이터만 사용\n",
    "        if len(Classes_inDataSet) == 1 :\n",
    "            # 라벨값 할당\n",
    "            cls_index = Classes_inDataSet.index(Classes_inDataSet[0]) # 클래스가 Classes_inDataSet 내에서 어떤 인덱스 번호를 갖고 있는가?\n",
    "            cls_onehot_inImage = np.eye(len(Classes_inDataSet))[cls_index]\n",
    "\n",
    "            Class_Label_list.apend(cls_onehot_inImage)\n",
    "\n",
    "            image = cv2.imread(image_file_list[count])\n",
    "            image = cv2.resize(image, (224, 224))/255\n",
    "            images_list.append(image)\n",
    "        \n",
    "        count = count + 1\n",
    "\n",
    "    return np.asarray(images_list), Class_Label_list"
   ]
  },
  {
   "source": [
    "# 모델 생성\n",
    "### 34개의 레이어를 가진 모델\n",
    "### 34개의 레이어에 Residual connection을 추가한 모델\n",
    "### 이렇게 2개를 만든다"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlainModel(tf.keras.Model):\n",
    "    def __init__(self, initializer, regularizer):\n",
    "        super(Detector, self).__init__(name='Detector')\n",
    "        # 레이어 \n",
    "        \n",
    "    \n",
    "    def call(self, Image, RoI_list): # input으로 (224,224,3)과 RoI를 받는다. RoI는 앞서 RPN에서 뽑아낸걸 쓴다. \n",
    "\n",
    "        return Classify_layer_output, Reg_layer_output # Classify_layer_output : [1,21] 텐서가 len(RoI_list)개 모인 리스트, Reg_layer_output : [1, 84] 텐서가 len(RoI_list)개 모인 리스트\n",
    "    \n",
    "    def get_grad(self, image, RoI_list, Reg_labels, Cls_labels, g_num, training_step): \n",
    "        \n",
    "        return g_list\n",
    "    \n",
    "    def App_Gradient(self, image, RoI_list, Reg_labels, Cls_labels, training_step) :\n",
    "        \n",
    "\n",
    "    def Training_model(self, image_list, RoI_list_forAllImage, Reg_labels_for_FastRCNN, Cls_labels_for_FastRCNN, training_step):"
   ]
  }
 ]
}
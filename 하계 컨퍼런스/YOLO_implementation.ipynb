{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOLOv1 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0., 10.,  0.,  0.])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.zeros((5))\n",
    "idx = int(2)\n",
    "test[idx] = 10\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from functools import partial\n",
    "import xmltodict\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 경로\n",
    "train_x_path = '/home/ubuntu/CUAI_2021/Advanced_Minkyu_Kim/PASCAL_VOC_2007/train/VOCdevkit/VOC2007/JPEGImages'\n",
    "train_y_path = '/home/ubuntu/CUAI_2021/Advanced_Minkyu_Kim/PASCAL_VOC_2007/train/VOCdevkit/VOC2007/Annotations'\n",
    "\n",
    "# 파일 경로 휙득\n",
    "list_train_x = sorted([x for x in glob(train_x_path + '/**')])    \n",
    "list_train_y = sorted([x for x in glob(train_y_path + '/**')]) \n",
    "\n",
    "image_file_path_list = sorted([x for x in glob(train_x_path + '/**')])\n",
    "xml_file_path_list = sorted([x for x in glob(train_y_path + '/**')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋에 존재하는 클래스가 얼마나 있는지 알아낸다\n",
    "def get_Classes_inImage(xml_file_list):\n",
    "    Classes_inDataSet = []\n",
    "\n",
    "    for xml_file_path in xml_file_list: \n",
    "\n",
    "        f = open(xml_file_path)\n",
    "        xml_file = xmltodict.parse(f.read())\n",
    "        # 사진에 객체가 여러개 있을 경우\n",
    "        try: \n",
    "            for obj in xml_file['annotation']['object']:\n",
    "                Classes_inDataSet.append(obj['name'].lower()) # 들어있는 객체 종류를 알아낸다\n",
    "        # 사진에 객체가 하나만 있을 경우\n",
    "        except TypeError as e: \n",
    "            Classes_inDataSet.append(xml_file['annotation']['object']['name'].lower()) \n",
    "        f.close()\n",
    "\n",
    "    Classes_inDataSet = list(set(Classes_inDataSet)) # set은 중복된걸 다 제거하고 유니크한? 아무튼 하나만 가져온다. 그걸 리스트로 만든다\n",
    "    Classes_inDataSet.sort() # 정렬\n",
    "\n",
    "    return Classes_inDataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지에 어떤 Ground Truth Box가 있는지(label 휙득)\n",
    "def get_label_fromImage(xml_file_path, Classes_inDataSet):\n",
    "\n",
    "    f = open(xml_file_path)\n",
    "    xml_file = xmltodict.parse(f.read()) \n",
    "\n",
    "    Image_Height = float(xml_file['annotation']['size']['height'])\n",
    "    Image_Width  = float(xml_file['annotation']['size']['width'])\n",
    "\n",
    "    label = np.zeros((7, 7, 25), dtype = np.float32)\n",
    "    \n",
    "    try:\n",
    "        for obj in xml_file['annotation']['object']:\n",
    "            \n",
    "            # class의 index 휙득\n",
    "            class_index = Classes_inDataSet.index(obj['name'].lower())\n",
    "            \n",
    "            # min, max좌표 얻기\n",
    "            x_min = float(obj['bndbox']['xmin']) \n",
    "            y_min = float(obj['bndbox']['ymin'])\n",
    "            x_max = float(obj['bndbox']['xmax']) \n",
    "            y_max = float(obj['bndbox']['ymax'])\n",
    "\n",
    "            # 224*224에 맞게 변형시켜줌\n",
    "            x_min = float((224.0/Image_Width)*x_min)\n",
    "            y_min = float((224.0/Image_Height)*y_min)\n",
    "            x_max = float((224.0/Image_Width)*x_max)\n",
    "            y_max = float((224.0/Image_Height)*y_max)\n",
    "\n",
    "            # 변형시킨걸 x,y,w,h로 만들기 \n",
    "            x = (x_min + x_max)/2.0\n",
    "            y = (y_min + y_max)/2.0\n",
    "            w = x_max - x_min\n",
    "            h = y_max - y_min\n",
    "\n",
    "            # x,y가 속한 cell알아내기\n",
    "            x_cell = int(x/32) # 0~6\n",
    "            y_cell = int(y/32) # 0~6\n",
    "            x_val_inCell = float((x - x_cell * 32.0)/32.0) # 0.0 ~ 1.0\n",
    "            y_val_inCell = float((y - y_cell * 32.0)/32.0) # 0.0 ~ 1.0\n",
    "\n",
    "            # w, h 를 0~1 사이의 값으로 만들기\n",
    "            w = w / 224.0\n",
    "            h = h / 224.0\n",
    "\n",
    "            class_index_inCell = class_index + 5\n",
    "\n",
    "            label[y_cell][x_cell][0] = x_val_inCell\n",
    "            label[y_cell][x_cell][1] = y_val_inCell\n",
    "            label[y_cell][x_cell][2] = w\n",
    "            label[y_cell][x_cell][3] = h\n",
    "            label[y_cell][x_cell][4] = 1.0\n",
    "            label[y_cell][x_cell][class_index_inCell] = 1.0\n",
    "\n",
    "\n",
    "    # single-object in image\n",
    "    except TypeError as e : \n",
    "        # class의 index 휙득\n",
    "        class_index = Classes_inDataSet.index(xml_file['annotation']['object']['name'].lower())\n",
    "            \n",
    "        # min, max좌표 얻기\n",
    "        x_min = float(xml_file['annotation']['object']['bndbox']['xmin']) \n",
    "        y_min = float(xml_file['annotation']['object']['bndbox']['ymin'])\n",
    "        x_max = float(xml_file['annotation']['object']['bndbox']['xmax']) \n",
    "        y_max = float(xml_file['annotation']['object']['bndbox']['ymax'])\n",
    "\n",
    "        # 224*224에 맞게 변형시켜줌\n",
    "        x_min = float((224.0/Image_Width)*x_min)\n",
    "        y_min = float((224.0/Image_Height)*y_min)\n",
    "        x_max = float((224.0/Image_Width)*x_max)\n",
    "        y_max = float((224.0/Image_Height)*y_max)\n",
    "\n",
    "        # 변형시킨걸 x,y,w,h로 만들기 \n",
    "        x = (x_min + x_max)/2.0\n",
    "        y = (y_min + y_max)/2.0\n",
    "        w = x_max - x_min\n",
    "        h = y_max - y_min\n",
    "\n",
    "        # x,y가 속한 cell알아내기\n",
    "        x_cell = int(x/32) # 0~6\n",
    "        y_cell = int(y/32) # 0~6\n",
    "        x_val_inCell = float((x - x_cell * 32.0)/32.0) # 0.0 ~ 1.0\n",
    "        y_val_inCell = float((y - y_cell * 32.0)/32.0) # 0.0 ~ 1.0\n",
    "\n",
    "        # w, h 를 0~1 사이의 값으로 만들기\n",
    "        w = w / 224.0\n",
    "        h = h / 224.0\n",
    "\n",
    "        class_index_inCell = class_index + 5\n",
    "\n",
    "        label[y_cell][x_cell][0] = x_val_inCell\n",
    "        label[y_cell][x_cell][1] = y_val_inCell\n",
    "        label[y_cell][x_cell][2] = w\n",
    "        label[y_cell][x_cell][3] = h\n",
    "        label[y_cell][x_cell][4] = 1.0\n",
    "        label[y_cell][x_cell][class_index_inCell] = 1.0\n",
    "\n",
    "    return label # np array로 반환\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 증강을 할거면 여기서 해야한다.\n",
    "def make_dataset(image_file_path_list, xml_file_path_list) :\n",
    "\n",
    "    Classes_inDataSet = get_Classes_inImage(xml_file_path_list)\n",
    "\n",
    "    image_dataset = 0\n",
    "    label_dataset = 0\n",
    "\n",
    "    for i in tqdm(range(0, len(image_file_path_list)), desc = \"make dataset\"):\n",
    "        image = cv2.imread(image_file_path_list[i]) / 255.0 # 이미지를 넘파이 배열로 불러온 뒤 255로 나눠 픽셀별 R, G, B를 0~1사이의 값으로 만들어버린다.\n",
    "        label = get_label_fromImage(xml_file_path_list[i], Classes_inDataSet)\n",
    "        \n",
    "        # 여기서 데이터 증강을 시도해야한다고 생각한다\n",
    "        # 랜덤한 값을 뽑아내고 만약 그 값이 0.5를 넘기면 데이터 증강의 대상이 되는 이미지가 되는거다.\n",
    "\n",
    "\n",
    "        if image_dataset == 0 : \n",
    "            image_dataset = image.copy()\n",
    "            label_dataset = label.copy()\n",
    "        else : \n",
    "            image_dataset = np.append(image_dataset, image)\n",
    "            label_dataset = np.append(label_dataset, label)\n",
    "    \n",
    "\n",
    "    image_dataset = np.reshape(image_dataset, (-1, 224, 224, 3))\n",
    "    label_dataset = np.reshape(label_dataset, (-1, 7, 7, 25))\n",
    "\n",
    "    return image_dataset, label_dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation\n",
    "출처 : https://towardsdatascience.com/complete-image-augmentation-in-opencv-31a6b02694f5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill(img, h, w):\n",
    "    img = cv2.resize(img, (h, w), cv2.INTER_CUBIC)\n",
    "    return img\n",
    "\n",
    "# 0.2로 설정하면 될듯(up to 20% of the original image size라고 해서)\n",
    "def horizontal_shift(img, ratio=0.0):\n",
    "    if ratio > 1 or ratio < 0:\n",
    "        print('Value should be less than 1 and greater than 0')\n",
    "        return img\n",
    "    ratio = random.uniform(-ratio, ratio)\n",
    "    h, w = img.shape[:2]\n",
    "    to_shift = w*ratio\n",
    "    if ratio > 0:\n",
    "        img = img[:, :int(w-to_shift), :]\n",
    "    if ratio < 0:\n",
    "        img = img[:, int(-1*to_shift):, :]\n",
    "    img = fill(img, h, w)\n",
    "    return img\n",
    "\n",
    "def vertical_shift(img, ratio=0.0):\n",
    "    if ratio > 1 or ratio < 0:\n",
    "        print('Value should be less than 1 and greater than 0')\n",
    "        return img\n",
    "    ratio = random.uniform(-ratio, ratio)\n",
    "    h, w = img.shape[:2]\n",
    "    to_shift = h*ratio\n",
    "    if ratio > 0:\n",
    "        img = img[:int(h-to_shift), :, :]\n",
    "    if ratio < 0:\n",
    "        img = img[int(-1*to_shift):, :, :]\n",
    "    img = fill(img, h, w)\n",
    "    return img\n",
    "\n",
    "def zoom(img, value): # 전체 이미지의 value(0~1)만큼만 가져가는거니까 20%면 0.8로?\n",
    "    if value > 1 or value < 0:\n",
    "        print('Value for zoom should be less than 1 and greater than 0')\n",
    "        return img\n",
    "    value = random.uniform(value, 1)\n",
    "    h, w = img.shape[:2]\n",
    "    h_taken = int(value*h)\n",
    "    w_taken = int(value*w)\n",
    "    h_start = random.randint(0, h-h_taken)\n",
    "    w_start = random.randint(0, w-w_taken)\n",
    "    img = img[h_start:h_start+h_taken, w_start:w_start+w_taken, :]\n",
    "    img = fill(img, h, w)\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 밝기 조정(The more the value of Saturation and Value matrices the greater is the brightness)\n",
    "\n",
    "def brightness(img, low, high): # low = 0.5, high = 1.5로 설정하면 될듯?\n",
    "    value = random.uniform(low, high) # low~high 사이 랜덤한 값을 기존 saturation에다 곱한다\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    hsv = np.array(hsv, dtype = np.float64)\n",
    "    hsv[:,:,1] = hsv[:,:,1]*value\n",
    "    hsv[:,:,1][hsv[:,:,1]>255]  = 255\n",
    "    hsv[:,:,2] = hsv[:,:,2]*value \n",
    "    hsv[:,:,2][hsv[:,:,2]>255]  = 255\n",
    "    hsv = np.array(hsv, dtype = np.uint8)\n",
    "    img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_num = len(tf.keras.applications.VGG16(weights='imagenet', include_top=False,  input_shape=(224, 224, 3)).layers) # 레이어 최대 개수\n",
    "\n",
    "YOLO = tf.keras.models.Sequential(name = \"YOLO\")\n",
    "for i in range(0, max_num-1):\n",
    "    YOLO.add(tf.keras.applications.VGG16(weights='imagenet', include_top=False,  input_shape=(224, 224, 3)).layers[i])\n",
    "\n",
    "initializer = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.01, seed=None)\n",
    "regularizer = tf.keras.regularizers.l2(0.0005) # L2 규제 == weight decay\n",
    "\n",
    "for layer in YOLO.layers:\n",
    "    # 'kernel_regularizer' 속성이 있는 인스턴스를 찾아 regularizer를 추가\n",
    "    if hasattr(layer, 'kernel_regularizer'):\n",
    "        setattr(layer, 'kernel_regularizer', regularizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 원문은 DarkNet을 썼지만 나는 구현을 쉽게 하기 위해 VGG16을 썼다.\n",
    "### 여기에 따로 레이어를 얹어서 YOLO를 구현할거다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "YOLO.add(tf.keras.layers.Conv2D(1024, (3, 3), kernel_initializer=initializer, padding = 'SAME' ,kernel_regularizer = regularizer, name = \"detection_conv1\", dtype='float32'))\n",
    "YOLO.add(tf.keras.layers.Conv2D(1024, (3, 3), kernel_initializer=initializer, padding = 'SAME' ,kernel_regularizer = regularizer, name = \"detection_conv2\", dtype='float32'))\n",
    "YOLO.add(tf.keras.layers.MaxPool2D((2, 2)))\n",
    "YOLO.add(tf.keras.layers.Conv2D(1024, (3, 3), kernel_initializer=initializer, padding = 'SAME' ,kernel_regularizer = regularizer, name = \"detection_conv3\", dtype='float32'))\n",
    "YOLO.add(tf.keras.layers.Conv2D(1024, (3, 3), kernel_initializer=initializer, padding = 'SAME' ,kernel_regularizer = regularizer, name = \"detection_conv4\", dtype='float32'))\n",
    "# Linear 부분\n",
    "YOLO.add(tf.keras.layers.Flatten())\n",
    "YOLO.add(tf.keras.layers.Dense(4096, activation= None, kernel_initializer = initializer, name = \"detection_linear1\", dtype='float32'))\n",
    "YOLO.add(tf.keras.layers.Dropout(.5))\n",
    "YOLO.add(tf.keras.layers.Dense(1470, activation=partial(tf.nn.leaky_relu, alpha=0.01), kernel_initializer = initializer, name = \"detection_linear2\", dtype='float32')) # 7*7*30 = 1470. 0~29 : (0, 0) 위치의 픽셀에 대한 각종 출력값, 30~59 : (1, 0) 위치의...블라블라\n",
    "YOLO.add(tf.keras.layers.Reshape((7, 7, 30), name = 'output', dtype='float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"YOLO\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "detection_conv1 (Conv2D)     (None, 14, 14, 1024)      4719616   \n",
      "_________________________________________________________________\n",
      "detection_conv2 (Conv2D)     (None, 14, 14, 1024)      9438208   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "detection_conv3 (Conv2D)     (None, 7, 7, 1024)        9438208   \n",
      "_________________________________________________________________\n",
      "detection_conv4 (Conv2D)     (None, 7, 7, 1024)        9438208   \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 50176)             0         \n",
      "_________________________________________________________________\n",
      "detection_linear1 (Dense)    (None, 4096)              205524992 \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "detection_linear2 (Dense)    (None, 1470)              6022590   \n",
      "_________________________________________________________________\n",
      "output (Reshape)             (None, 7, 7, 30)          0         \n",
      "=================================================================\n",
      "Total params: 259,296,510\n",
      "Trainable params: 259,296,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "YOLO.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_multitask_loss(y_true, y_pred): # 커스텀 손실함수\n",
    "    \n",
    "        # 계산을 위해 y_true을 tensor로 만들어준다. \n",
    "        y_true = tf.convert_to_tensor(y_true)\n",
    "\n",
    "        # box = [x,y,w,h,confidence_score]\n",
    "        pred_box_batch_1 = y_pred[..., :4] # [-1,7,7,4]\n",
    "        pred_confidence_batch_1 = y_pred[..., 4] # [-1,7,7,1]\n",
    "        pred_box_batch_2 = y_pred[..., 5:9] # [-1,7,7,4]\n",
    "        pred_confidence_batch_2 = y_pred[..., 9] # [-1,7,7,1]\n",
    "        pred_class_batch = y_pred[..., 10:] # [-1,7,7,20]\n",
    "\n",
    "        # y_true는 ground truth box(0~4) + class(5~24)로 구성되어 있다 \n",
    "        true_box_batch = y_true[..., :4] # [-1,7,7,5]\n",
    "        true_confidence_batch = y_true[..., 4] # [-1,7,7,1]\n",
    "        true_class_batch = y_true[..., 5:] # [-1,7,7,20]\n",
    "\n",
    "        # YOLOv1의 Loss function은 3개로 나뉜다. localization, confidence, classification\n",
    "        # localization은 추측한 box랑 ground truth box의 오차\n",
    "        # confidencee는 Pr(Object) * IOU, classification은 Pr(Class|Object) = 객체가 있을 때 해당 객체일 확률이다. 어떻게 계산하지?\n",
    "\n",
    "        loss = tf.Variable(0.0)\n",
    "        count = 0.0\n",
    "        # loss를 계산 \n",
    "        for boxes_pred_1, confidences_pred_1, boxes_pred_2, confidences_pred_2, class_pred, boxes_true, confidences_true, class_true in pred_box_batch_1, pred_confidence_batch_1, pred_box_batch_2, pred_confidence_batch_2, pred_class_batch, true_box_batch, true_confidence_batch, true_class_batch :\n",
    "                # boxes_pred_1 : [7,7,4], boxes_pred_2 : [7,7,4], boxes_true : [7,7,4], class_pred : [7,7,20], class_true : [7,7,20], pred_confidences_1 : [7, 7, 1], pred_confidences_2 : [7, 7, 1]\n",
    "                boxes_pred_1 = tf.reshape(boxes_pred_1, [49, 4])\n",
    "                confidences_pred_1 = tf.reshape(confidences_pred_1, [49, 1])\n",
    "                boxes_pred_2 = tf.reshape(boxes_pred_2, [49, 4])\n",
    "                confidences_pred_2 = tf.reshape(confidences_pred_2, [49, 1])\n",
    "                class_pred = tf.reshape(boxes_pred_2, [49, 20])\n",
    "\n",
    "                boxes_true = tf.reshape(boxes_true, [49, 4])\n",
    "                confidences_true = tf.reshape(confidences_true, [49, 1])\n",
    "                class_true = tf.reshape(class_true, [49, 20])\n",
    "\n",
    "                for box_pred_1, confidence_pred_1, box_pred_2, confidence_pred_2, class_pred_oneCell, box_true, confidence_true, class_true_oneCell in boxes_pred_1, confidences_pred_1, boxes_pred_2, confidences_pred_2, class_pred, boxes_true, confidences_true, class_true :\n",
    "                        # 한 셀에서 responsible한 box를 골라 localization error를 구해야함. reponsible한 box가 아니면 손실값은 0이 되며 confidence loss, classification loss를 구할 때도 reponsible한 box일 경우에만 계산을 수행함.\n",
    "                        # responsible한 box는 IoU를 기준으로 판단함\n",
    "\n",
    "                        # IoU 구하기\n",
    "                        # x,y,w,h -> min_x, min_y, max_x, max_y로 변환\n",
    "                        box_pred_1_np = box_pred_1.numpy()\n",
    "                        box_pred_2_np = box_pred_2.numpy()\n",
    "                        box_true_np = box_true.numpy()\n",
    "\n",
    "                        box_pred_1_area = box_pred_1_np[2] * box_pred_1_np[3]\n",
    "                        box_pred_2_area = box_pred_2_np[2] * box_pred_2_np[3]\n",
    "                        box_true_area  = box_true_np[2]  * box_true_np[3]\n",
    "\n",
    "                        box_pred_1_minmax = np.asarray([box_pred_1_np[0] - 0.5*box_pred_1_np[2], box_pred_1_np[1] - 0.5*box_pred_1_np[3], box_pred_1_np[0] + 0.5*box_pred_1_np[2], box_pred_1_np[1] + 0.5*box_pred_1_np[3]])\n",
    "                        box_pred_2_minmax = np.asarray([box_pred_2_np[0] - 0.5*box_pred_2_np[2], box_pred_2_np[1] - 0.5*box_pred_2_np[3], box_pred_2_np[0] + 0.5*box_pred_2_np[2], box_pred_2_np[1] + 0.5*box_pred_2_np[3]])\n",
    "                        box_true_minmax = np.asarray([box_true_np[0] - 0.5*box_true_np[2], box_true_np[1] - 0.5*box_true_np[3], box_true_np[0] + 0.5*box_true_np[2], box_true_np[1] + 0.5*box_true_np[3]])\n",
    "\n",
    "                        # 곂치는 영역의 (min_x, min_y, max_x, max_y)\n",
    "                        InterSection_pred_1_with_true = [max(box_pred_1_minmax[0], box_true_minmax[0]), max(box_pred_1_minmax[1], box_true_minmax[1]), min(box_pred_1_minmax[2], box_true_minmax[2]), min(box_pred_1_minmax[3], box_true_minmax[3])]\n",
    "                        InterSection_pred_2_with_true = [max(box_pred_2_minmax[0], box_true_minmax[0]), max(box_pred_2_minmax[1], box_true_minmax[1]), min(box_pred_2_minmax[2], box_true_minmax[2]), min(box_pred_2_minmax[3], box_true_minmax[3])]\n",
    "\n",
    "                        # 박스별로 IoU를 구한다\n",
    "                        IntersectionArea_pred_1_true = 0\n",
    "\n",
    "                        # 음수 * 음수 = 양수일 수도 있으니 검사를 한다.\n",
    "                        if (InterSection_pred_1_with_true[2] - InterSection_pred_1_with_true[0] + 1) >= 0 and (InterSection_pred_1_with_true[3] - InterSection_pred_1_with_true[1] + 1) >= 0 :\n",
    "                                IntersectionArea_pred_1_true = (InterSection_pred_1_with_true[2] - InterSection_pred_1_with_true[0] + 1) * InterSection_pred_1_with_true[3] - InterSection_pred_1_with_true[1] + 1\n",
    "\n",
    "                        IntersectionArea_pred_2_true = 0\n",
    "\n",
    "                        if (InterSection_pred_2_with_true[2] - InterSection_pred_2_with_true[0] + 1) >= 0 and (InterSection_pred_2_with_true[3] - InterSection_pred_2_with_true[1] + 1) >= 0 :\n",
    "                                IntersectionArea_pred_2_true = (InterSection_pred_2_with_true[2] - InterSection_pred_2_with_true[0] + 1) * InterSection_pred_2_with_true[3] - InterSection_pred_2_with_true[1] + 1\n",
    "\n",
    "                        Union_pred_1_true = box_pred_1_area + box_true_area - IntersectionArea_pred_1_true\n",
    "                        Union_pred_2_true = box_pred_2_area + box_true_area - IntersectionArea_pred_2_true\n",
    "\n",
    "                        IoU_box_1 = IntersectionArea_pred_1_true/Union_pred_1_true\n",
    "                        IoU_box_2 = IntersectionArea_pred_2_true/Union_pred_2_true\n",
    "                        \n",
    "                        responsible_IoU = 0\n",
    "                        responsible_box = 0\n",
    "                        responsible_bbox_confidence = 0\n",
    "                        nonresponsible_bbox_confidence = 0\n",
    "\n",
    "                        # box1, box2 중 responsible한걸 선택(IoU 기준)\n",
    "                        if IoU_box_1 >= IoU_box_2 :\n",
    "                                responsible_IoU = IoU_box_1\n",
    "                                responsible_box = tf.identity(box_pred_1)\n",
    "                                responsible_bbox_confidence = tf.identity(confidence_pred_1)\n",
    "                                non_responsible_bbox_confidence = tf.identity(confidence_pred_2)\n",
    "                                \n",
    "                        else :\n",
    "                                responsible_IoU = IoU_box_2\n",
    "                                responsible_box = tf.identity(box_pred_2)\n",
    "                                responsible_bbox_confidence = tf.identity(confidence_pred_2)\n",
    "                                non_responsible_bbox_confidence = tf.identity(confidence_pred_1)\n",
    "                        \n",
    "                        # 만약 해당 cell에 객체가 없으면 confidence error의 no object 파트만 판단. (label된 값에서 알아서 해결)\n",
    "                        # 0~3 : bbox1의 위치 정보, 4 : bbox1의 bbox confidence score, 5~8 : bbox2의 위치 정보, 9 : bbox2의 confidence score, 10~29 : cell에 존재하는 클래스 확률 = pr(class | object) \n",
    "\n",
    "                        # localization error 구하기(x,y,w,h). x, y는 해당 grid cell의 중심 좌표와 offset이고 w, h는 전체 이미지에 대해 정규화된 값이다. 즉, 범위가 0~1이다.\n",
    "                        localization_err_x = tf.math.pow( tf.math.subtract(box_true[0], responsible_box[0]), 2) # (x-x_hat)^2\n",
    "                        localization_err_y = tf.math.pow( tf.math.subtract(box_true[1], responsible_box[1]), 2) # (y-y_hat)^2\n",
    "\n",
    "                        localization_err_w = tf.math.pow( tf.math.subtract(tf.math.pow(box_true[2], 0.5), tf.math.pow(responsible_box[2], 0.5)), 2) # (sqrt(w) - sqrt(w_hat))^2\n",
    "                        localization_err_h = tf.math.pow( tf.math.subtract(tf.math.pow(box_true[3], 0.5), tf.math.pow(responsible_box[3], 0.5)), 2) # (sqrt(h) - sqrt(h_hat))^2\n",
    "                        \n",
    "                        localization_err_1 = tf.math.add(localization_err_x, localization_err_y)\n",
    "                        localization_err_2 = tf.math.add(localization_err_w, localization_err_h)\n",
    "                        localization_err = tf.math.add(localization_err_1, localization_err_2)\n",
    "                        weighted_localization_err = tf.math.multiply(localization_err, 5.0) # 5.0 : λ_coord\n",
    "                        # confidence error 구하기. true의 경우 답인 객체는 1 * ()고 아니면 0*()가 된다. \n",
    "                        # index 4, 9에 있는 값(0~1)이 해당 박스에 객체가 있을 확률을 나타낸거다. Pr(obj in bbox)\n",
    "                        class_confidence_score = tf.math.add(tf.math.pow(tf.math.subtract(responsible_bbox_confidence, confidence_true), 2), \n",
    "                                                             tf.math.multiply(tf.math.pow(tf.math.subtract(non_responsible_bbox_confidence, confidence_true), 2), 0.5) ) \n",
    "                        \n",
    "\n",
    "                        # classification loss(10~29. 인덱스 10~29에 해당되는 값은 Pr(Classi |Object)이다. 객체가 cell안에 있을 때 해당 객체일 확률\n",
    "                        # class_true_oneCell는 진짜 객체는 1이고 나머지는 0일거다. \n",
    "                        classification_err = tf.reduce_sum(tf.math.multiply(tf.math.subtract(class_true_oneCell, class_pred_oneCell), tf.math.subtract(class_true_oneCell, class_pred_oneCell)))\n",
    "\n",
    "                        # loss합체\n",
    "                        loss_OneCell_1 = tf.math.add(weighted_localization_err, class_confidence_score)\n",
    "                        loss_OneCell = tf.math.add(loss_OneCell_1, classification_err)\n",
    "                        loss = tf.math.add(loss, loss_OneCell)\n",
    "                count = count + 1.0\n",
    "        \n",
    "        # 배치에 대한 loss 구하기\n",
    "        tot_loss = tf.math.divide(loss, count)\n",
    "\n",
    "        return tot_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 훈련 계획\n",
    "## epoch : 135\n",
    "## batch size : 64\n",
    "## momentum : 0.9\n",
    "## weight decay : 0.0005\n",
    "## learning rate : 0.01(1~75), 0.001(76~105), 0.0001(106~135)\n",
    "\n",
    "## data augmentation : random scaling, translation을 원래 이미지 사이즈의 20%까지만 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"We continue training with 10−2 for 75 epochs, then 10−3 for 30 epochs, and finally 10−4 for 30 epochs\" 구현\n",
    "\n",
    "LR_SCHEDULE = [\n",
    "    # (epoch to start, learning rate) tuples\n",
    "    (0, 1e-2), (75, 1e-3), (105, 1e-4)\n",
    "]\n",
    "\n",
    "def lr_schedule(epoch, lr):\n",
    "  \"\"\"Helper function to retrieve the scheduled learning rate based on epoch.\"\"\"\n",
    "  if epoch < LR_SCHEDULE[0][0] or epoch > LR_SCHEDULE[-1][0]:\n",
    "    return lr\n",
    "  for i in range(len(LR_SCHEDULE)):\n",
    "    if epoch == LR_SCHEDULE[i][0]:\n",
    "      return LR_SCHEDULE[i][1]\n",
    "  return lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-546b1fef0285>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myolo_multitask_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m YOLO.fit(x_train, y_train,\n\u001b[0m\u001b[1;32m      6\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m135\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.RMSprop(lr = 1e-2, momentum=0.9)\n",
    "\n",
    "YOLO.compile(loss = yolo_multitask_loss, optimizer=optimizer)\n",
    "\n",
    "YOLO.fit(x_train, y_train,\n",
    "          batch_size=64,\n",
    "          epochs=135,\n",
    "          verbose=0,\n",
    "          callbacks=[tf.keras.callbacks.LearningRateScheduler(lr_schedule)])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5de1033c4b6bab6c838dd6f2b29357493acb89b798a708ce20db74bb033faa6b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('python_tensorflow': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
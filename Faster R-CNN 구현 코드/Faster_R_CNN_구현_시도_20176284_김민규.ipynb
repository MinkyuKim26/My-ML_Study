{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "dec8a5ff48d192d3613b9e6713a72fe103c8e5d5c44dc7b8ee41f3376e4a4f37"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Faster R-CNN 구현\n",
    "### 텐서플로우 기반\n",
    "### 주석은 한글 위주로 작성"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import xmltodict\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from PIL import Image, ImageDraw"
   ]
  },
  {
   "source": [
    "## 훈련 이미지 가져오기"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_path = '/Users/minguinho/Documents/AI_Datasets/PASCAL_VOC_2007/train/VOCdevkit/VOC2007/JPEGImages'\n",
    "train_y_path = '/Users/minguinho/Documents/AI_Datasets/PASCAL_VOC_2007/train/VOCdevkit/VOC2007/Annotations'\n",
    "\n",
    "test_x_path = '/Users/minguinho/Documents/AI_Datasets/PASCAL_VOC_2007/test/VOCdevkit/VOC2007/JPEGImages'\n",
    "test_y_path = '/Users/minguinho/Documents/AI_Datasets/PASCAL_VOC_2007/test/VOCdevkit/VOC2007/Annotations'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "5011\n4952\n"
     ]
    }
   ],
   "source": [
    "list_train_x = sorted([x for x in glob.glob(train_x_path + '/**')])    \n",
    "list_train_y = sorted([x for x in glob.glob(train_y_path + '/**')]) \n",
    "\n",
    "list_test_x = sorted([x for x in glob.glob(test_x_path + '/**')])    \n",
    "list_test_y = sorted([x for x in glob.glob(test_y_path + '/**')]) \n",
    "\n",
    "print(len(list_train_x))\n",
    "print(len(list_test_x))"
   ]
  },
  {
   "source": [
    "훈련용 이미지는 5011개, 테스트용 이미지는 4952개가 있음을 알 수 있다. 그리고 둘다 x, y값이 존재한다. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 논문 흐름대로 코드 작성하려고 노력할 것"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 공용으로 사용하는 레이어 생성 \n",
    "### ImageNet을 위해 훈련된 VGG16을 일부 가져온다"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nblock1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n_________________________________________________________________\nblock1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n_________________________________________________________________\nblock1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n_________________________________________________________________\nblock2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n_________________________________________________________________\nblock2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n_________________________________________________________________\nblock2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n_________________________________________________________________\nblock3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n_________________________________________________________________\nblock3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n_________________________________________________________________\nblock3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n_________________________________________________________________\nblock3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n_________________________________________________________________\nblock4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n_________________________________________________________________\nblock4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n_________________________________________________________________\nblock4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n_________________________________________________________________\nblock4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n_________________________________________________________________\nblock5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n=================================================================\nTotal params: 14,714,688\nTrainable params: 14,714,688\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "max_num = len(tf.keras.applications.VGG16(weights='imagenet', include_top=False,  input_shape=(224, 224, 3)).layers) # 레이어 최대 개수\n",
    "\n",
    "SharedConvNet = tf.keras.models.Sequential()\n",
    "for i in range(0, max_num-1):\n",
    "    SharedConvNet.add(tf.keras.applications.VGG16(weights='imagenet', include_top=False,  input_shape=(224, 224, 3)).layers[i])\n",
    "\n",
    "SharedConvNet.summary() # 13개의 레이어 공유(컨볼루션 레이어 10개, 풀링 레이어 3개). 논문에선 14*14라는데 아씨 모르겠다"
   ]
  },
  {
   "source": [
    "## RPN - 앵커 준비\n",
    "#### 입력 이미지 기준으로 앵커를 생성한다.\n",
    "#### 풀링을 3번 하므로 2^3 = 8이니 (8, 8)부터 (16, 8)...등 8픽셀식 중심 좌표를 옮겨가며 앵커들을 k개씩 생성한다\n",
    "#### 생성한 앵커들 중 사용할 가치가 있는 앵커를 걸러낸다(이미지 범위를 벗어나지 않는 앵커들만 선정)\n",
    "#### 선정한 앵커 중 실제 물체의 box와 얼마나 곂치는지(IoU) 계산해본다. 확실히 겹친다 하는 애들을 Positive 앵커로, 거의 안겹친다 하는 애들은 Negataive 앵커로 선정한다. 애매한 애들은 거른다.\n",
    "#### 이렇게 생성된 앵커들로 미니배치를 생성한다. Positive 128개, Negative 128개로 만드는게 ideal한 구성이긴 한데 Positive한 앵커가 별로 없다. 그래서 Positive를 128개 못채웠으면 Negataive 앵커로 채워준다. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3 # 논문에서 n은 VGG16을 거치고 나온 특성맵 위를 슬라이딩 할 커널의 크기\n",
    "\n",
    "# 생성할 앵커 크기는? \n",
    "anchor_size = [32, 64, 128] # 이미지 크기가 224*224라 32, 64, 128로 지정\n",
    "anchor_aspect_ratio = [[1,1],[1,0.5], [0.5,1]] # W*L기준 \n"
   ]
  },
  {
   "source": [
    "### 앵커를 만들어(224*224 기준) -> 여기서 positive 앵커, negative 앵커로 나눠 -> 얘들을 좀 비율 맞게 조합해서 256개의 앵커 그룹(미니배치)를 만들어 -> RPN훈련에 사용해"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 함수로 만드는 이유?\n",
    "#### 이미지 별로 라벨에서 박스 좌표랑 객체 종류 뽑아내서 loss를 계산해야한다. 그래서 코드의 간결화?를 위해 함수를 만드는 것"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 앵커 생성 함수. \n",
    "def make_anchor(anchor_size, anchor_aspect_ratio, image_size = 224) :\n",
    "    # 입력 이미지(그래봤자 224*224긴 하지만)에 맞춰 앵커를 생성해보자 \n",
    "\n",
    "    anchors = [] # [x,y,w,h]로 이루어진 리스트 \n",
    "\n",
    "    # 앵커 중심좌표 간격\n",
    "    # 왜 간격이 8이냐? pooling을 3번 했기 때문에 각 특성맵의 픽셀 하나하나가 원래 이미지에서 8*8 픽셀을 대표하는 값들이다\n",
    "    # 즉, 특성맵의 각 좌표 위를 슬라이딩 할건데 센터 좌표를 하나씩 건넌다는건 원래 이미지에서 8픽셀씩 움직인다는 것과 같다. \n",
    "    # 그렇기에 간격을 8*8로 설정한 것이다 \n",
    "    interval_x = 16 \n",
    "    interval_y = 16\n",
    "    Center_max_x = 208 # 224 - 16, 중심좌표가 224가 될 수는 없다.\n",
    "    Center_max_y = 208 # 224 - 16\n",
    "\n",
    "    # 2단 while문 생성\n",
    "    x = 16\n",
    "    y = 16\n",
    "    while(y <= 208):\n",
    "        while(x <= 208):\n",
    "            # k개의 앵커 생성. 여기서 k = len(anchor_size) * len(anchor_aspect_ratio)다\n",
    "            for i in range(0, len(anchor_size)) : \n",
    "                for j in range(0, len(anchor_aspect_ratio)) :\n",
    "                    anchor_width = anchor_aspect_ratio[j][0] * anchor_size[i]\n",
    "                    anchor_height = anchor_aspect_ratio[j][1] * anchor_size[i]\n",
    "                    # 얘를 사용할 수 있는 앵커인가? 필터링\n",
    "                    if((x - (anchor_width/2) >= 0) and (y - (anchor_height/2) >= 0) and\n",
    "                    (x + (anchor_width/2) <= 224) and (y + (anchor_height/2) <= 224)):\n",
    "                        # 조건이 맞다고 판단되면 앵커 생성\n",
    "                        anchor = [x, y, anchor_width, anchor_height]\n",
    "                        anchors.append(anchor)\n",
    "            x = x + interval_x \n",
    "        y = y + interval_y\n",
    "        x = 16\n",
    "    return anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1117"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "anchors = make_anchor(anchor_size, anchor_aspect_ratio, 224)\n",
    "\n",
    "len(anchors) # 4181개의 앵커 생성. 이 앵커 집합은 모든 이미지 입력에 적용할 앵커다"
   ]
  },
  {
   "source": [
    "#### 각 입력 이미지에서 객체의 Ground_Truth_Box, Class를 추출해야한다\n",
    "#### Ground_Truth_Box는 RPN에서 IoU 구하는데 사용하기도 하고  Loss에서도 사용하기도 한다"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### Loss 사용을 위해 Class list도 만들자.\n",
    "#### 논문의 loss 함수를 보면 pi가 있다. pi는 리스트인데 PASCAL VOC에 존재하는 객체들이 몇 %의 확률로 있느냐 나타내는거다\n",
    "#### 이를 위해 어떤 객체들이 PASCAL VOC에 존재하는지 알아야한다. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label 추출을 위한 label 파일 리스트. label 정보가 xml파일 안에 있다.\n",
    "xml_file_list = sorted([x for x in glob.glob(train_y_path + '/**')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 존재하는 객체 종류를 알아내자\n",
    "def get_Classes_inImage():\n",
    "    classes = []\n",
    "\n",
    "    for xml_file_path in xml_file_list: \n",
    "\n",
    "        f = open(xml_file_path)\n",
    "        xml_file = xmltodict.parse(f.read())\n",
    "        # 사진에 객체가 여러개 있을 경우\n",
    "        try: \n",
    "            for obj in xml_file['annotation']['object']:\n",
    "                classes.append(obj['name'].lower()) # 들어있는 객체 종류를 알아낸다\n",
    "        # 사진에 객체가 하나만 있을 경우\n",
    "        except TypeError as e: \n",
    "            classes.append(xml_file['annotation']['object']['name'].lower()) \n",
    "        f.close()\n",
    "\n",
    "    classes = list(set(classes)) # set은 중복된걸 다 제거하고 유니크한? 아무튼 하나만 가져온다. 그걸 리스트로 만든다\n",
    "    classes.sort() # 정렬\n",
    "\n",
    "    return classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_classes = get_Classes_inImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IoU를 위한 Ground_Truth_Box와 Loss를 위한 Class 리스트를 얻는다. \n",
    "def get_label_fromImage(xml_file_path):\n",
    "\n",
    "    f = open(xml_file_path)\n",
    "    xml_file = xmltodict.parse(f.read()) \n",
    "\n",
    "    # 우선 원래 이미지 크기를 얻는다. 왜냐하면 앵커는 224*224 기준으로 만들었는데 원본 이미지는 224*224가 아니기 때문.\n",
    "    # 224*224에 맞게 줄일려고 하는거다\n",
    "    Image_Width = float(xml_file['annotation']['size']['height'])\n",
    "    Image_Height  = float(xml_file['annotation']['size']['width'])\n",
    "\n",
    "\n",
    "    Classes_list = [] \n",
    "    Ground_Truth_Box_list = [] \n",
    "\n",
    "    # multi-objects in image\n",
    "    try:\n",
    "        for obj in xml_file['annotation']['object']:\n",
    "            obj_class = obj['name'].lower() \n",
    "            # 박스 좌표(왼쪽 위, 오른쪽 아래) 얻기\n",
    "            x_min = float(obj['bndbox']['xmin']) \n",
    "            y_min = float(obj['bndbox']['ymin'])\n",
    "            x_max = float(obj['bndbox']['xmax']) \n",
    "            y_max = float(obj['bndbox']['ymax'])\n",
    "\n",
    "            # 224*224에 맞게 변형시켜줌\n",
    "            x_min = float((224/Image_Width)*x_min)\n",
    "            y_min = float((224/Image_Height)*y_min)\n",
    "            x_max = float((224/Image_Width)*x_max)\n",
    "            y_max = float((224/Image_Height)*y_max)\n",
    "\n",
    "\n",
    "            # 얘들을 앵커랑 같은 양식으로 저장(x,y,w,h)\n",
    "            Center_x = (x_min + x_max)/2\n",
    "            Center_y = (y_min + y_max)/2\n",
    "            Ground_Truth_Box_Width = x_max - x_min\n",
    "            Ground_Truth_Box_Height = y_max - y_min\n",
    "\n",
    "            Ground_Truth_Box = [Center_x, Center_y, Ground_Truth_Box_Width, Ground_Truth_Box_Height] \n",
    "\n",
    "            index = label_classes.index(obj_class) \n",
    "\n",
    "            Classes_list.append(index)\n",
    "            Ground_Truth_Box_list.append(Ground_Truth_Box)\n",
    "\n",
    "    # single-object in image\n",
    "    except TypeError as e : \n",
    "        \n",
    "        obj_class = xml_file['annotation']['object']['name'] \n",
    "        # 박스 좌표(왼쪽 위, 오른쪽 아래) 얻기\n",
    "        x_min = float(xml_file['annotation']['object']['bndbox']['xmin']) \n",
    "        y_min = float(xml_file['annotation']['object']['bndbox']['ymin']) \n",
    "        x_max = float(xml_file['annotation']['object']['bndbox']['xmax']) \n",
    "        y_max = float(xml_file['annotation']['object']['bndbox']['ymax']) \n",
    "\n",
    "        # 224*224에 맞게 변형시켜줌\n",
    "        x_min = float((224/Image_Width)*x_min)\n",
    "        y_min = float((224/Image_Height)*y_min)\n",
    "        x_max = float((224/Image_Width)*x_max)\n",
    "        y_max = float((224/Image_Height)*y_max)\n",
    "\n",
    "\n",
    "        # 얘들을 앵커랑 같은 양식으로 저장(x,y,w,h)\n",
    "        Center_x = (x_min + x_max)/2\n",
    "        Center_y = (y_min + y_max)/2\n",
    "        Ground_Truth_Box_Width = x_max - x_min\n",
    "        Ground_Truth_Box_Height = y_max - y_min\n",
    "\n",
    "        Ground_Truth_Box = [Center_x, Center_y, Ground_Truth_Box_Width, Ground_Truth_Box_Height] \n",
    "\n",
    "        index = label_classes.index(obj_class) \n",
    "\n",
    "        Classes_list.append(index)\n",
    "        Ground_Truth_Box_list.append(Ground_Truth_Box)\n",
    "\n",
    "\n",
    "    return Classes_list, Ground_Truth_Box_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[8, 8, 8, 8, 8]\n[[175.31733333333335, 123.20000000000002, 36.437333333333356, 57.34400000000001], [124.84266666666667, 142.464, 52.56533333333334, 48.384], [21.504, 138.432, 37.03466666666667, 58.239999999999995], [160.08533333333332, 110.432, 32.256, 47.03999999999999], [175.91466666666668, 90.944, 20.906666666666666, 15.232]]\n"
     ]
    }
   ],
   "source": [
    "# 테스트. xml_file_list[1]에 해당하는 이미지를 갖고 학습한다고 가정\n",
    "Class_label, Ground_Truth_Box_list = get_label_fromImage(xml_file_list[0])\n",
    "print(Class_label) # car가 이미지에 있고\n",
    "print(Ground_Truth_Box_list) # 224*224로 변환했을 때 약 (215, 85) 좌표에 (241, 125) 크기의 Ground_Truth_Box가 있음을 알 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 앵커들을 Positive, Negative 앵커로 나누자\n",
    "def align_anchor(xml_file_path):\n",
    "    Positive_Anchor = []\n",
    "    Negative_Anchor = []\n",
    "\n",
    "    Claases_RelativeToPositiveAnchor = [] # Positive Anchor와 연관있는 클래스의 인덱스\n",
    "    GroundTruthBox_RelativeToPositiveAnchor = [] # Positive Anchor와 연관있는 클래스의 박스\n",
    "\n",
    "    # 미니배치에서 Negative Anchor와 연관있는 클래스의 인덱스, 박스가 필요한 경우가 있을 수 있다. 그러니 저장한다\n",
    "    Claases_RelativeToNegativeAnchor = []\n",
    "    GroundTruthBox_RelativeToNegativeAnchor = []\n",
    "\n",
    "    Classes_list, Ground_Truth_Box_list = get_label_fromImage(xml_file_path) \n",
    "\n",
    "    for i in range(0, len(anchors)): # 모든 앵커에 대한 IoU 계산\n",
    "        # 각 앵커에 대해 존재하는 모든 Ground_Truth_Box의 IoU를 계산한다.\n",
    "        # 어떤 객체든 IoU가 0.7이 넘어가면 바로 Positive 를 붙혀준다.\n",
    "        IoU_list = [] \n",
    "        \n",
    "        for j in range(0, len(Ground_Truth_Box_list)):\n",
    "            # IoU 계산\n",
    "            # 왼쪽 x좌표 기준으로는 ground_truth와 anchor 중 max를, 오른쪽 기준으로는 min값을 사용한다.\n",
    "            # 그림을 그려서 왼쪽 좌표끼리 묶어서 max, 오른쪽 좌표끼리 묶어서 min을 선택해보면 이해가 쉬울거다.\n",
    "            Ground_Truth_Box_min_x = Ground_Truth_Box_list[j][0] - (Ground_Truth_Box_list[j][2]/2)\n",
    "            Ground_Truth_Box_min_y = Ground_Truth_Box_list[j][1] - (Ground_Truth_Box_list[j][3]/2)\n",
    "            Ground_Truth_Box_max_x = Ground_Truth_Box_list[j][0] + (Ground_Truth_Box_list[j][2]/2)\n",
    "            Ground_Truth_Box_max_y = Ground_Truth_Box_list[j][1] + (Ground_Truth_Box_list[j][3]/2)\n",
    "            \n",
    "            anchor_min_x = anchors[i][0] - (anchors[i][2]/2)\n",
    "            anchor_min_y = anchors[i][1] - (anchors[i][3]/2)\n",
    "            anchor_max_x = anchors[i][0] + (anchors[i][2]/2)\n",
    "            anchor_max_y = anchors[i][1] + (anchors[i][3]/2)\n",
    "\n",
    "            IoU_minX = max(anchor_min_x, Ground_Truth_Box_min_x)\n",
    "            IoU_minY = max(anchor_max_x, Ground_Truth_Box_max_x)\n",
    "            IoU_maxX = min(anchor_min_x, Ground_Truth_Box_min_x)\n",
    "            IoU_maxY = min(anchor_min_x, Ground_Truth_Box_min_x)\n",
    "\n",
    "            Intersection_Area = ((IoU_maxX - IoU_minX) * (IoU_maxY - IoU_minY)) # 교집합 넓이\n",
    "            Union_Area = (anchors[i][2] * anchors[i][3]) + (Ground_Truth_Box_list[j][2] * Ground_Truth_Box_list[j][3]) - Intersection_Area # 합집합 넓이?\n",
    "\n",
    "            IoU = Intersection_Area/Union_Area # IoU를 구했다\n",
    "\n",
    "            IoU_list.append(IoU)\n",
    "\n",
    "        # Ground_Truth_Box별로 IoU를 얻었다. 이제 Positive, Negative Anchor를 구분하자.\n",
    "        # Loss에서 박스 위치관련 로스 계산할 때 어떤 객체의 박스를 기준으로 positive 앵커가 되었는지 물어본다. 그래서 그것도 저장하려고 한다.  \n",
    "        for j in range(0, len(IoU_list)):\n",
    "            # Positive는 기준이 2개 있긴하지만 난 2번 기준(IoU가 0.7 이상)만 쓰겠다. any groud_truth_box에 대한 IoU가 0.7보다 크면 된다. \n",
    "            if IoU_list[j] > 0.7 : \n",
    "                Positive_Anchor.append(anchors[i])\n",
    "                Classes_RelativeToPositiveAnchor.append(Classes_list[j])\n",
    "                GroundTruthBox_RelativeToPositiveAnchor(Ground_Truth_Box_list[j])\n",
    "                break\n",
    "        # Negative는 IoU가 0.3보다 작은 앵커를 사용한다. 모든 Ground_Truth_Box에 대한 IoU가 0.3보다 작은 앵커가 negative 앵커다.\n",
    "        if max(IoU_list) < 0.3 : \n",
    "            index = IoU_list.index(max(IoU_list))\n",
    "            Negative_Anchor.append(anchors[i])\n",
    "            Classes_RelativeToNegativeAnchor.append(Classes_list[index])\n",
    "            GroundTruthBox_RelativeToNegativeAnchor.append(Ground_Truth_Box_list[index])\n",
    "\n",
    "\n",
    "    \n",
    "    return Positive_Anchor, Negative_Anchor, Classes_RelativeToPositiveAnchor, GroundTruthBox_RelativeToPositiveAnchor, Classes_RelativeToNegativeAnchor, GroundTruthBox_RelativeToNegativeAnchor\n"
   ]
  },
  {
   "source": [
    "### 훈련을 위한 미니배치 256(positive 128, negative 128개) 선발"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Create_Minibatch(Positive_Anchor, Negative_Anchor, Classes_RelativeToPositiveAnchor, GroundTruthBox_RelativeToPositiveAnchor, Classes_RelativeToNegativeAnchor, GroundTruthBox_RelativeToNegativeAnchor) : \n",
    "\n",
    "    max_for = min([120, len(Positive_Anchor)])\n",
    "\n",
    "    ran_list = random.sample(range(0, max_for), 120)\n",
    "    Anchor_Minibatch = []\n",
    "    Claases_RelativeToPositiveAnchor_forMinibatch = [] # reg Loss에 쓰임\n",
    "    GroundTruthBox_RelativeToPositiveAnchor_forMinibatch = [] # reg Loss에 쓰임\n",
    "    for random_num in ran_list :\n",
    "        Anchor_Minibatch.append(Positive_Anchor[random_num])\n",
    "        Claases_RelativeToPositiveAnchor_forMinibatch.append(Claases_RelativeToPositiveAnchor[random_num])\n",
    "        GroundTruthBox_RelativeToPositiveAnchor_forMinibatch(GroundTruthBox_RelativeToPositiveAnchor[random_num])\n",
    "\n",
    "    # positive Anchor가 120개 미만일 경우 negative anchor에서 빈걸 채워줌\n",
    "    ran_list = random.sample(range(0, len(Negative_Anchor)), 120 - len(GroundTruthBox_RelativeToPositiveAnchor_forMinibatch))\n",
    "\n",
    "    if len(GroundTruthBox_RelativeToPositiveAnchor_forMinibatch) < 120 :\n",
    "        for random_num in ran_list :\n",
    "            Anchor_Minibatch.append(Negative_Anchor[random_num])\n",
    "            Claases_RelativeToPositiveAnchor_forMinibatch.append(Classes_RelativeToNegativeAnchor[random_num])\n",
    "            GroundTruthBox_RelativeToPositiveAnchor_forMinibatch(GroundTruthBox_RelativeToNegativeAnchor[random_num])\n",
    "\n",
    "    # 이제 negative 앵커\n",
    "    ran_list = random.sample(range(0, len(Negative_Anchor)), 120) # 랜덤성 증가?를 위해 또다시 난수 생성\n",
    "    for random_num in ran_list :\n",
    "        Anchor_Minibatch.append(Negative_Anchor[random_num])\n",
    "    # 0~127까지 Positive, 128~255까지 Negative\n",
    "\n",
    "    return Anchor_Minibatch, Claases_RelativeToPositiveAnchor_forMinibatch, GroundTruthBox_RelativeToPositiveAnchor_forMinibatch"
   ]
  },
  {
   "source": [
    "### Loss 함수 생성"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ouput_forLoss(cls_layer_output, reg_layer_output, Anchor_Minibatch):\n",
    "    # cls_layer_output는 18개의 채널을 가진 14*14 특성맵이다. (14*14*18)\n",
    "    # reg_layer_output는 36개의 채널을 가진 14*14 특성맵이다. (14*14*36)\n",
    "\n",
    "    # 출력값 중 loss함수를 위해 선별되는 것들\n",
    "    reg_layer_output_forMinibatch = []\n",
    "    cls_layer_output_forMinibatch = []\n",
    "\n",
    "    for Anchor in Anchor_Minibatch :\n",
    "        # '특성맵에서' 앵커의 중심좌표\n",
    "        anchor_x_inFeatureMap = (Anchor[0]/16) - 1\n",
    "        anchor_y_inFeatureMap = (Anchor[1]/16) - 1\n",
    "\n",
    "        anchor_index = 0 # 9개의 앵커가 있다고 헸다\n",
    "\n",
    "        # anchor_size = [32, 64, 128]\n",
    "        # anchor_aspect_ratio = [[1,1],[1,0.5], [0.5,1]]\n",
    "        # 앵커 생성할 때 [32,32], [32,16], [16, 32], [64, 64]...순서로 만들었기에 여기선 [32,32] 앵커의 인덱스를 0이라 설정한다. \n",
    "\n",
    "        aspect_ratio = Anchor[2]/Anchor[3]\n",
    "        if aspect_ratio == 1 : \n",
    "            if Anchor[2] == 32 :\n",
    "                anchor_index = 0\n",
    "            elif Anchor[2] == 64 :\n",
    "                anchor_index = 3\n",
    "            elif Anchor[2] == 128 :\n",
    "                anchor_index = 6\n",
    "\n",
    "        elif aspect_ratio == 0.5 : \n",
    "            if Anchor[2] == 32 :\n",
    "                anchor_index = 1\n",
    "            elif Anchor[2] == 64 :\n",
    "                anchor_index = 4\n",
    "            elif Anchor[2] == 128 :\n",
    "                anchor_index = 7\n",
    "\n",
    "        elif aspect_ratio == 2 : \n",
    "            if Anchor[2] == 32 :\n",
    "                anchor_index = 2\n",
    "            elif Anchor[2] == 64 :\n",
    "                anchor_index = 5\n",
    "            elif Anchor[2] == 128 :\n",
    "                anchor_index = 8\n",
    "        \n",
    "        cls_output_forThisAnchor = [cls_layer_output[anchor_x_inFeatureMap][anchor_y_inFeatureMap][anchor_index], cls_layer_output[anchor_x_inFeatureMap][anchor_y_inFeatureMap][anchor_index + 1]]\n",
    "        reg_output_forThisAnchor = [reg_layer_output[anchor_x_inFeatureMap][anchor_y_inFeatureMap][anchor_index], cls_layer_output[anchor_x_inFeatureMap][anchor_y_inFeatureMap][anchor_index + 1], reg_layer_output[anchor_x_inFeatureMap][anchor_y_inFeatureMap][anchor_index + 2], cls_layer_output[anchor_x_inFeatureMap][anchor_y_inFeatureMap][anchor_index + 3]] # (x, y, w, h로 지정)\n",
    "\n",
    "        cls_layer_output_forMinibatch.append(cls_output_forThisAnchor)\n",
    "        reg_layer_output_forMinibatch.append(reg_output_forThisAnchor)\n",
    "        \n",
    "    return cls_layer_output_forMinibatch, reg_layer_output_forMinibatch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Smooth_L1(ti, ti_star) :\n",
    "    difference_ti = ti - ti_star\n",
    "    smooth_L1 = 0\n",
    "    if abs(difference_ti) < 1: smooth_L1 = 0.5 * (difference_ti * difference_ti)\n",
    "    else : smooth_L1 = abs(difference_ti) - 0.5\n",
    "\n",
    "    return smooth_L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss_Regression. Lreg에 해당\n",
    "def Loss_Regression(predict_box, anchor_box, groundTruth_box) : \n",
    "    # 와씨..이게 그 가스라이팅? 그거냐?\n",
    "    # predict_box는 36개의 앵커박스 구성요소, 한 픽셀에 대한 36개의 앵커박스의 x,y,w,h가 쫘르륵...있는건데 거기서 x,y,w,h 한웅큼 가져온거다.\n",
    "    # x,y,w,h로 가져오는건 뭐 알아서 하겠지...미래의 내가\n",
    "    t_x = (predict_box[0] - anchor_box[0])/anchor_box[2]\n",
    "    t_y = (predict_box[1] - anchor_box[1])/anchor_box[3]\n",
    "    t_w = math.log10(predict_box[2]/anchor_box[2])\n",
    "    t_h = math.log10(predict_box[3]/anchor_box[3])\n",
    "\n",
    "    t_x_star = (groundTruth_box[0] - anchor_box[0])/anchor_box[2]\n",
    "    t_y_star = (groundTruth_box[1] - anchor_box[1])/anchor_box[3]\n",
    "    t_w_star = math.log10(groundTruth_box[2]/anchor_box[2])\n",
    "    t_h_star = math.log10(groundTruth_box[3]/anchor_box[3])\n",
    "\n",
    "    # Smooth L1 구하기\n",
    "    # 구성요소가 4개니까 4번 구해야겠지?\n",
    "    smooth_L1_x = Smooth_L1(t_x, t_x_star)\n",
    "    smooth_L1_y = Smooth_L1(t_y, t_y_star)\n",
    "    smooth_L1_w = Smooth_L1(t_w, t_w_star)\n",
    "    smooth_L1_h = Smooth_L1(t_h, t_h_star)\n",
    "\n",
    "    smooth_L1_list = [smooth_L1_x, smooth_L1_y, smooth_L1_w, smooth_L1_h]\n",
    "\n",
    "    return smooth_L1_list # 모아서 반환\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L_cls\n",
    "def Loss_Classes(cls_layer_output, pi_ground_truth) :\n",
    "    log_loss = -pi_ground_truth*math.log10(cls_layer_output[0])-(1-pi_ground_truth)*math.log10(1-cls_layer_output)\n",
    "    return log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss함수 수행. 입력 이미지의 라벨값을 받는다.\n",
    "# loss는 아웃풋을 뽑아낸 뒤에 얻어야한다. \n",
    "def Loss_RPN(cls_layer_output, reg_layer_output, xml_file_path): # RPN에서 최종 결과값인 reg_layer와 cls layer의 output, 그리고 라벨이 들어있는 파일\n",
    "\n",
    "    Positive_Anchor, Negative_Anchor, Claases_RelativeToPositiveAnchor, GroundTruthBox_RelativeToPositiveAnchor = align_anchor(xml_file_path) # 앵커 분류\n",
    "\n",
    "    Anchor_Minibatch, Claases_RelativeToPositiveAnchor_forMinibatch, GroundTruthBox_RelativeToPositiveAnchor_forMinibatch = Create_Minibatch(Positive_Anchor, Negative_Anchor, Claases_RelativeToPositiveAnchor, GroundTruthBox_RelativeToPositiveAnchor) # 미니배치\n",
    "\n",
    "    \n",
    "\n",
    "    # 자, 여기서 잠깐 생각을 해보자\n",
    "    # k = 9로 했으니 cls_layer의 결과값은 18개, reg_layer의 결과값은 36개가 있다. \n",
    "    # 앵커를 256개 랜덤해서 뽑겠다는 말이니까 결과값도 256쌍을 뽑아야한다. 그렇지? 이 256쌍은 뽑힌 앵커에 해당하는 출력값을 뽑아야한다. \n",
    "    cls_layer_output_forMinibatch, reg_layer_output_forMinibatch = get_ouput_forLoss(cls_layer_output, reg_layer_output, Anchor_Minibatch) # 선발된 앵커에 맞춰 output도 걸러낸다\n",
    "\n",
    "    N_cls = len(Anchor_Minibatch)\n",
    "    N_reg = 14*14 # VGG 특성맵 최종 output 넓이. 근데 이거 바꿔야한다. 28*28이 아니라 14*14더라\n",
    "    lambda_forLoss = 10\n",
    "\n",
    "    Lcls_sum = 0\n",
    "    Lreg_sum = 0\n",
    "\n",
    "    # RPN의 cls output이 pi, reg  output이 ti이다.\n",
    "    # k = 9일 때 pi는 18개, ti는 36개라는 말.\n",
    "    for i in range(0, len(Anchor_Minibatch)) :\n",
    "        pi_ground_truth = 0\n",
    "        if i < 128 : # Positive Anchor\n",
    "            pi_ground_truth = 1\n",
    "        #Lcls(classes loss)\n",
    "        Lcls_sum = Lcls_sum + Loss_Classes(cls_layer_output_forMinibatch[i], pi_ground_truth)\n",
    "\n",
    "        #Lreg(regression loss)\n",
    "        if i < 128 : \n",
    "            Lreg_sum = Lreg_sum + pi_ground_truth * Loss_Regression(reg_layer_output_forMinibatch, Anchor_Minibatch[i], GroundTruthBox_RelativeToPositiveAnchor_forMinibatch[i])\n",
    "\n",
    "    loss = (1/N_cls) * Lcls_sum + lambda_forLoss*(1/N_reg)*Lreg_sum\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "source": [
    "### RPN 생성"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = len(anchor_size) * len(anchor_aspect_ratio) # 3*3 = 9\n",
    "\n",
    "initializer = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.01, seed=None)\n",
    "\n",
    "RPN_intermediate_layer = tf.keras.layers.Conv2D(512, (n,n), activation='relu', padding='VALID', kernel_initializer = initializer, input_shape=(14, 14, 512))\n",
    "RPN_cls_Layer = tf.keras.layers.Conv2D(2*k, (1,1), activation='sigmoid', padding='VALID', kernel_initializer = initializer,input_shape=(14, 14, 512)) # 클래스인가? 아닌가? \n",
    "RPN_reg_Layer = tf.keras.layers.Conv2D(4*k, (1,1), activation='relu', padding='VALID', kernel_initializer = initializer,input_shape=(14, 14, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file_list = sorted([x for x in glob.glob(train_x_path + '/**')])\n",
    "xml_file_list = sorted([x for x in glob.glob(train_y_path + '/**')]) # 있긴한데 또 만들었다. 통일성을 위해."
   ]
  },
  {
   "source": [
    "## 훈련을 위한 함수"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력용 이미지 생성. 224, 224로 변환시켜준다. \n",
    "def make_input():\n",
    "    \n",
    "    images_list = []\n",
    "    \n",
    "    for i in tqdm(range(0, len(image_file_list))) :\n",
    "        \n",
    "        image = cv2.imread(image_file_list[i])\n",
    "        image = cv2.resize(image, (224, 224))/255\n",
    "        \n",
    "        images_list.append(image)\n",
    "    \n",
    "    return np.asarray(images_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 공유해서 사용할 특성맵 리스트들을 출력하자\n",
    "def make_Shared_ConvLayer_FeatureMap(SharedConvNet) :\n",
    "    image_list = make_input()\n",
    "\n",
    "    shared_Conv_output_list = np.array([])\n",
    "    for i in tqdm(range(0, len(image_list))): \n",
    "        shared_Conv_output = SharedConvNet(np.expand_dims(image_list[i], axis=0))\n",
    "        shared_Conv_output_list = np.append(shared_Conv_output_list, shared_Conv_output)\n",
    "\n",
    "    return shared_Conv_output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_RPN(shared_Conv_output_list, RPN_intermediate_layer, RPN_cls_Layer, RPN_reg_Layer) :\n",
    "\n",
    "    for i in tqdm(Range(0, len(image_file_list))) :\n",
    "        input_label_path = xml_file_list[i]\n",
    "    \n",
    "        intermedi_output = RPN_intermediate_layer(np.expand_dims(shared_Conv_output_list[i], axis=0)) # 출력 = 레이어(입력)\n",
    "        cls_layer_output = RPN_cls_Layer(intermedi_output)\n",
    "        reg_layer_output = RPN_reg_Layer(intermedi_output)\n",
    "\n",
    "        # 각 이미지에서 미니배치를 선발 -> 손실 구하기(한 입력값에 대한 손실)\n",
    "        loss = Loss_RPN(cls_layer_output, reg_layer_output, xml_file_list[i])\n",
    "\n",
    "        # 학습률 0.001 for 60k mini batch, 학습률 0.0001 for next 20k mini-batches\n",
    "        # momentum : 0.9, weight decay : 0.0005\n",
    "\n",
    "\n",
    "    return RPN_intermediate_layer, RPN_cls_Layer, RPN_reg_Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여러가지 앵커를 ground_truth_box와 IoU 비교후 앵커들을 선정 -> RoI로 사용.\n",
    "# RoI에 해당하는 영역을 특성맵에서 찾아야하는데 RoI는 224*224 기준이고 특성맵은 14*14임. -> 특성맵에 틀어맞게 RoI를 변환 -> 변환했으니 14*14 내부에 RoI가 변환되어 있음 -> 변환되어있는 RoI들을 FCs 2개에 넣어줌 -> 'class 레이어'와 'box 위치 분류 레이어' 두 곳에 넣어줌\n",
    "# Roi Pooling만 잘 구현하면 되겠는데...어찌 구현할까(21/4/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 5011/5011 [00:17<00:00, 286.52it/s]\n",
      "100%|██████████| 5011/5011 [2:03:40<00:00,  1.48s/it]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'Range' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-f8148d5ad238>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# 결과값이 어떻게 나올까? 궁금하다\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_file_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mintermedi_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRPN_intermediate_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshared_Conv_output_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 출력 = 레이어(입력)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mcls_layer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRPN_cls_Layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermedi_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Range' is not defined"
     ]
    }
   ],
   "source": [
    "shared_Conv_output_list = make_Shared_ConvLayer_FeatureMap(SharedConvNet)\n",
    "\n",
    "cls_layer_output_list = np.array([])\n",
    "reg_layer_output_list = np.array([])\n",
    "\n",
    "# 결과값이 어떻게 나올까? 궁금하다\n",
    "for i in tqdm(range(0, len(image_file_list))) :\n",
    "    intermedi_output = RPN_intermediate_layer(np.expand_dims(shared_Conv_output_list[i], axis=0)) # 출력 = 레이어(입력)\n",
    "    cls_layer_output = RPN_cls_Layer(intermedi_output)\n",
    "    reg_layer_output = RPN_reg_Layer(intermedi_output)\n",
    "\n",
    "    cls_layer_output_list = np.append(cls_layer_output_list, cls_layer_output)\n",
    "    reg_layer_output_list = np.append(reg_layer_output_list, reg_layer_output)"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Fast RCNN의 로스(따로 만들어야한다. 위에 Loss는 RPN의 Loss다.), 모델 구조를 만들고 4-step 교차 훈련방법을 사용하자\n",
    "<br>\n",
    "그리고 로스를 이용해 가중치를 업데이트하는 방법(수동으로)을 알아야한다. 이걸 모르면 진행이 안된다. \n",
    "<br>\n",
    "근데 그 방법을 알면 바로 만들 수 있다. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}
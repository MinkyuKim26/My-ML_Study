{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "dec8a5ff48d192d3613b9e6713a72fe103c8e5d5c44dc7b8ee41f3376e4a4f37"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Faster R-CNN 구현\n",
    "### 텐서플로우 기반\n",
    "### 주석은 한글 위주로 작성"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import xmltodict\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from PIL import Image, ImageDraw"
   ]
  },
  {
   "source": [
    "## 훈련 이미지 가져오기"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_path = '/Users/minguinho/Documents/AI_Datasets/PASCAL_VOC_2007/train/VOCdevkit/VOC2007/JPEGImages'\n",
    "train_y_path = '/Users/minguinho/Documents/AI_Datasets/PASCAL_VOC_2007/train/VOCdevkit/VOC2007/Annotations'\n",
    "\n",
    "test_x_path = '/Users/minguinho/Documents/AI_Datasets/PASCAL_VOC_2007/test/VOCdevkit/VOC2007/JPEGImages'\n",
    "test_y_path = '/Users/minguinho/Documents/AI_Datasets/PASCAL_VOC_2007/test/VOCdevkit/VOC2007/Annotations'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "5011\n4952\n"
     ]
    }
   ],
   "source": [
    "list_train_x = sorted([x for x in glob.glob(train_x_path + '/**')])    \n",
    "list_train_y = sorted([x for x in glob.glob(train_y_path + '/**')]) \n",
    "\n",
    "list_test_x = sorted([x for x in glob.glob(test_x_path + '/**')])    \n",
    "list_test_y = sorted([x for x in glob.glob(test_y_path + '/**')]) \n",
    "\n",
    "print(len(list_train_x))\n",
    "print(len(list_test_x))"
   ]
  },
  {
   "source": [
    "훈련용 이미지는 5011개, 테스트용 이미지는 4952개가 있음을 알 수 있다. 그리고 둘다 x, y값이 존재한다. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## RPN - 앵커 준비\n",
    "#### 입력 이미지 기준으로 앵커를 생성한다.\n",
    "#### 풀링을 3번 하므로 2^3 = 8이니 (8, 8)부터 (16, 8)...등 8픽셀식 중심 좌표를 옮겨가며 앵커들을 k개씩 생성한다\n",
    "#### 생성한 앵커들 중 사용할 가치가 있는 앵커를 걸러낸다(이미지 범위를 벗어나지 않는 앵커들만 선정)\n",
    "#### 선정한 앵커 중 실제 물체의 box와 얼마나 곂치는지(IoU) 계산해본다. 확실히 겹친다 하는 애들을 Positive 앵커로, 거의 안겹친다 하는 애들은 Negataive 앵커로 선정한다. 애매한 애들은 거른다.\n",
    "#### 이렇게 생성된 앵커들로 미니배치를 생성한다. Positive 128개, Negative 128개로 만드는게 ideal한 구성이긴 한데 Positive한 앵커가 별로 없다. 그래서 Positive를 128개 못채웠으면 Negataive 앵커로 채워준다. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 함수로 만드는 이유?\n",
    "#### 이미지 별로 라벨에서 박스 좌표랑 객체 종류 뽑아내서 loss를 계산해야한다. 그래서 코드의 간결화?를 위해 함수를 만드는 것"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 앵커 생성 함수. \n",
    "def make_anchor(anchor_size, anchor_aspect_ratio) :\n",
    "    # 입력 이미지(그래봤자 224*224긴 하지만)에 맞춰 앵커를 생성해보자 \n",
    "\n",
    "    anchors = [] # [x,y,w,h]로 이루어진 리스트 \n",
    "    valid_anchor_bool = [] # 이 앵커를 훈련에 쓸건가? 각 앵커별로 사용 여부를 나타낸다. \n",
    "\n",
    "    # 앵커 중심좌표 간격\n",
    "    interval_x = 16\n",
    "    interval_y = 16\n",
    "    Center_max_x = 208 # 224 - 16, 중심좌표가 224가 될 수는 없다.\n",
    "    Center_max_y = 208 # 224 - 16\n",
    "\n",
    "    # 2단 while문 생성\n",
    "    x = 8\n",
    "    y = 8\n",
    "    index_count = 0\n",
    "    while(y <= 224): # 8~208 = 14개 \n",
    "        while(x <= 224): # 8~208 = 14개 \n",
    "            # k개의 앵커 생성. 여기서 k = len(anchor_size) * len(anchor_aspect_ratio)다\n",
    "            for i in range(0, len(anchor_size)) : \n",
    "                for j in range(0, len(anchor_aspect_ratio)) :\n",
    "                    anchor_width = anchor_aspect_ratio[j][0] * anchor_size[i]\n",
    "                    anchor_height = anchor_aspect_ratio[j][1] * anchor_size[i]\n",
    "\n",
    "                    anchor = [x, y, anchor_width, anchor_height]\n",
    "                    anchors.append(anchor)\n",
    "                    # 앵커가 이미지 경계선을 넘나드나? 필터링\n",
    "                    if((x - (anchor_width/2) >= 0) and (y - (anchor_height/2) >= 0) and\n",
    "                    (x + (anchor_width/2) <= 224) and (y + (anchor_height/2) <= 224)):\n",
    "                        # 경계 안에 있으면 1\n",
    "                        valid_anchor_bool.append(1)\n",
    "                    else :\n",
    "                        valid_anchor_bool.append(0)\n",
    "            x = x + interval_x \n",
    "        y = y + interval_y\n",
    "        x = 8\n",
    "    return np.array(anchors), np.array(valid_anchor_bool) # 넘파이로 반환"
   ]
  },
  {
   "source": [
    "#### Loss 사용을 위해 Class list도 만들자.\n",
    "#### 논문의 loss 함수를 보면 pi가 있다. pi는 리스트인데 PASCAL VOC에 존재하는 객체들이 몇 %의 확률로 있느냐 나타내는거다\n",
    "#### 이를 위해 어떤 객체들이 PASCAL VOC에 존재하는지 알아야한다. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 하나에 대한 라벨값(어떤 클래스가 있는지, 그 클래스는 어떤 박스를 갖고 있는지)\n",
    "def get_label_fromImage(xml_file_path, Classes_inDataSet): # xml_file_path은 파일 하나의 경로를 나타낸다\n",
    "\n",
    "    f = open(xml_file_path)\n",
    "    xml_file = xmltodict.parse(f.read()) \n",
    "\n",
    "    # 우선 원래 이미지 크기를 얻는다. 왜냐하면 앵커는 224*224 기준으로 만들었는데 원본 이미지는 224*224가 아니기 때문.\n",
    "    # 224*224에 맞게 줄일려고 하는거다\n",
    "    Image_Height = float(xml_file['annotation']['size']['height'])\n",
    "    Image_Width  = float(xml_file['annotation']['size']['width'])\n",
    "\n",
    "\n",
    "    Classes_list = [] \n",
    "    Ground_Truth_Box_list = [] \n",
    "    class_label_list = [] # 원-핫 인코딩으로 만든 y값. 이건 Fast R-CNN 학습에 쓰인다.\n",
    "\n",
    "    # multi-objects in image\n",
    "    try:\n",
    "        for obj in xml_file['annotation']['object']:\n",
    "            obj_class = obj['name'].lower() \n",
    "            # 박스 좌표(왼쪽 위, 오른쪽 아래) 얻기\n",
    "            x_min = float(obj['bndbox']['xmin']) \n",
    "            y_min = float(obj['bndbox']['ymin'])\n",
    "            x_max = float(obj['bndbox']['xmax']) \n",
    "            y_max = float(obj['bndbox']['ymax'])\n",
    "\n",
    "            # 224*224에 맞게 변형시켜줌\n",
    "            x_min = float((224/Image_Width)*x_min)\n",
    "            y_min = float((224/Image_Height)*y_min)\n",
    "            x_max = float((224/Image_Width)*x_max)\n",
    "            y_max = float((224/Image_Height)*y_max)\n",
    "\n",
    "            Ground_Truth_Box = [x_min, y_min, x_max, y_max] \n",
    "\n",
    "            index = Classes_inDataSet.index(obj_class) \n",
    "\n",
    "            Classes_list.append(index)\n",
    "            Ground_Truth_Box_list.append(Ground_Truth_Box)\n",
    "\n",
    "    # single-object in image\n",
    "    except TypeError as e : \n",
    "        \n",
    "        obj_class = xml_file['annotation']['object']['name'] \n",
    "        # 박스 좌표(왼쪽 위, 오른쪽 아래) 얻기\n",
    "        x_min = float(xml_file['annotation']['object']['bndbox']['xmin']) \n",
    "        y_min = float(xml_file['annotation']['object']['bndbox']['ymin']) \n",
    "        x_max = float(xml_file['annotation']['object']['bndbox']['xmax']) \n",
    "        y_max = float(xml_file['annotation']['object']['bndbox']['ymax']) \n",
    "\n",
    "        # 224*224에 맞게 변형시켜줌\n",
    "        x_min = float((224/Image_Width)*x_min)\n",
    "        y_min = float((224/Image_Height)*y_min)\n",
    "        x_max = float((224/Image_Width)*x_max)\n",
    "        y_max = float((224/Image_Height)*y_max)\n",
    "\n",
    "        Ground_Truth_Box = [x_min, y_min, x_max, y_max]  \n",
    "\n",
    "        index = Classes_inDataSet.index(obj_class) \n",
    "\n",
    "        Classes_list.append(index)\n",
    "        Ground_Truth_Box_list.append(Ground_Truth_Box)\n",
    "\n",
    "\n",
    "    for i in range(0, len(Classes_list)):\n",
    "        one_hot = []\n",
    "        for j in range(0, len(Classes_inDataSet) + 1): # k + 1 클래스(사물 + 배경)를 원-핫 인코딩\n",
    "            if Classes_list[i] == j :\n",
    "                one_hot.append(1)\n",
    "            \n",
    "            else :\n",
    "                 one_hot.append(0)\n",
    "        class_label_list.append(one_hot)\n",
    "\n",
    "\n",
    "    return np.array(class_label_list), np.array(Ground_Truth_Box_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iou(anchor, Ground_Truth_Box_List) : # anchor, ground truth box list를 받아 각 IOU을 계산하고 제일 큰걸 반환\n",
    "\n",
    "    IoU_max = float(0.0)\n",
    "    index_ground_truth_box = -1\n",
    "    for i in range(0, len(Ground_Truth_Box_List)):\n",
    "\n",
    "        ground_truth_box = Ground_Truth_Box_List[i]\n",
    "\n",
    "        InterSection_min_x = max(anchor[0], ground_truth_box[0])\n",
    "        InterSection_min_y = max(anchor[1], ground_truth_box[1])\n",
    "\n",
    "        InterSection_max_x = min(anchor[2], ground_truth_box[2])\n",
    "        InterSection_max_y = min(anchor[3], ground_truth_box[3])\n",
    "\n",
    "        InterSection_Area = 0\n",
    "\n",
    "        if (InterSection_max_x - InterSection_min_x + 1) >= 0 and (InterSection_max_y - InterSection_min_y + 1) >= 0 :\n",
    "            InterSection_Area = (InterSection_max_x - InterSection_min_x + 1) * (InterSection_max_y - InterSection_min_y + 1)\n",
    "\n",
    "        box1_area = (anchor[2] - anchor[0]) * (anchor[3] - anchor[1])\n",
    "        box2_area = (ground_truth_box[2] - ground_truth_box[0]) * (ground_truth_box[3] - ground_truth_box[1])\n",
    "        Union_Area = box1_area + box2_area - InterSection_Area\n",
    "\n",
    "        IoU = (InterSection_Area/Union_Area)\n",
    "        if IoU > IoU_max :\n",
    "            IoU_max = IoU\n",
    "            index_ground_truth_box = i\n",
    "\n",
    "    return IoU_max, index_ground_truth_box # 어떤 박스와 IoU가 제일 높았는지\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 앵커들을 Positive, Negative 앵커로 나누자\n",
    "def align_anchor(anchors, valid_anchor_bool, Ground_Truth_Box_list):\n",
    "\n",
    "    # 각 앵커는 해당 위치에서 구한 여러가지 Ground truth Box와의 ioU 중 제일 높은거만 가져온다. \n",
    "    IoU_List = np.array([])\n",
    "    index_ground_truth_box_list = []\n",
    "    for i in range(0, len(anchors)):\n",
    "        anchor_minX = anchors[i][0] - (anchors[i][2]/2)\n",
    "        anchor_minY = anchors[i][1] - (anchors[i][3]/2)\n",
    "        anchor_maxX = anchors[i][0] + (anchors[i][2]/2)\n",
    "        anchor_maxY = anchors[i][1] + (anchors[i][3]/2)\n",
    "\n",
    "        anchor = [anchor_minX, anchor_minY, anchor_maxX, anchor_maxY]\n",
    "        IoU, index_ground_truth_box = get_iou(anchor, Ground_Truth_Box_list)\n",
    "        IoU_List = np.append(IoU_List, IoU)\n",
    "        index_ground_truth_box_list.append(index_ground_truth_box)\n",
    "\n",
    "    # positive, negative 앵커 분류\n",
    "    for i in range(0, 14*14):\n",
    "        # 각 위치에서 IoU가 가장 큰 앵커 or IoU가 0.7 넘는 앵커를 positive앵커로 한다. \n",
    "        for num in range(0, 9):\n",
    "            index = 9 * i + num\n",
    "            IoU_inOneSpot = IoU_List[9 * i : 9 * i + 9]\n",
    "\n",
    "            maxIoU_inOneSpot = max(IoU_inOneSpot)\n",
    "            if IoU_List[index] < 0.3 : # negative anchor\n",
    "                valid_anchor_bool[index] = 1\n",
    "            elif maxIoU_inOneSpot == IoU_List[index] or IoU_List[index] > 0.7 : # positive anchor\n",
    "                valid_anchor_bool[index] = 2\n",
    "            else: # 애매한 앵커들\n",
    "                valid_anchor_bool[index] = 0\n",
    "\n",
    "\n",
    "    return valid_anchor_bool, np.array(index_ground_truth_box_list) # 모든 앵커에 대한 ground truth box list. 앖으면 -1"
   ]
  },
  {
   "source": [
    "### 훈련을 위한 미니배치 256(positive 128, negative 128개) 선발"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Create_Minibatch(anchors, index_ground_truth_box_list, valid_anchor_bool) : \n",
    "\n",
    "    anchors_forMiniBatch = np.array([])\n",
    "    index_ground_truth_box_list_forMiniBatch = np.array([])\n",
    "    index_pos = np.array([]) # 긍정 앵커의 인덱스\n",
    "    index_neg = np.array([]) # 부정 앵커의 인덱스\n",
    "    output_index_forMiniBatch = np.array([])\n",
    "    for i in range(0, len(valid_anchor_bool)):\n",
    "        if valid_anchor_bool[i] == 2:\n",
    "            index_pos = np.append(index_pos, i)\n",
    "        elif valid_anchor_bool[i] == 1:\n",
    "            index_neg = np.append(index_neg, i)\n",
    "\n",
    "    max_for = min([128, len(index_pos)])\n",
    "\n",
    "    ran_list = random.sample(range(0, len(index_pos)), max_for)\n",
    "    for i in range(0, len(ran_list)) :\n",
    "        pos_index = int(index_pos[ran_list[i]])\n",
    "        anchors_forMiniBatch = np.append(anchors_forMiniBatch, anchors[pos_index])\n",
    "        output_index_forMiniBatch = np.append(output_index_forMiniBatch, pos_index)\n",
    "        index_ground_truth_box_list_forMiniBatch = np.append(index_ground_truth_box_list_forMiniBatch, index_ground_truth_box_list[pos_index])\n",
    "\n",
    "    # positive Anchor가 128개 미만일 경우 negative anchor에서 빈걸 채워줌\n",
    "    ran_list = random.sample(range(0, len(index_neg)), 256 - max_for) # 랜덤성 증가?를 위해 또다시 난수 생성\n",
    "    for i in range(0, len(ran_list)) :\n",
    "        neg_index = int(index_neg[[ran_list[i]]])\n",
    "        anchors_forMiniBatch = np.append(anchors_forMiniBatch, anchors[neg_index])\n",
    "        output_index_forMiniBatch = np.append(output_index_forMiniBatch, neg_index)\n",
    "\n",
    "    anchors_forMiniBatch = np.reshape(anchors_forMiniBatch, (-1,4))\n",
    "\n",
    "    return anchors_forMiniBatch, index_ground_truth_box_list_forMiniBatch, output_index_forMiniBatch, max_for # 미니배치와 어디서부터 negative 앵커가 시작되는지"
   ]
  },
  {
   "source": [
    "### Loss 함수 생성"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### RPN의 Output을 Loss에 쓰기 위해 필터링"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output_anchor_forLoss(cls_layer_output, reg_layer_output, output_index_forMiniBatch): # 가공한 출력값 중 미니배치에 맞춰 256개 선발\n",
    "\n",
    "    cls_layer_output_forMiniBatch = np.array([])\n",
    "    reg_layer_output_forMiniBatch = np.array([])\n",
    "\n",
    "    cls_layer_output = np.reshape(cls_layer_output, (-1, 2))\n",
    "    reg_layer_output = np.reshape(reg_layer_output, (-1, 4))\n",
    "\n",
    "    for i in range(0, len(output_index_forMiniBatch)):\n",
    "        index = int(output_index_forMiniBatch[i])\n",
    "        cls_layer_output_forMiniBatch = np.append(cls_layer_output_forMiniBatch, cls_layer_output[index])\n",
    "        reg_layer_output_forMiniBatch = np.append(reg_layer_output_forMiniBatch, reg_layer_output[index])\n",
    "        \n",
    "    cls_layer_output_forMiniBatch = np.reshape(cls_layer_output_forMiniBatch, (-1, 2))\n",
    "    reg_layer_output_forMiniBatch = np.reshape(reg_layer_output_forMiniBatch, (-1, 4))\n",
    "\n",
    "\n",
    "    return cls_layer_output_forMiniBatch, reg_layer_output_forMiniBatch"
   ]
  },
  {
   "source": [
    "### Loss 계산을 위한 함수"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Smooth_L1(ti, ti_star) :\n",
    "    difference_ti = ti - ti_star\n",
    "    smooth_L1 = 0\n",
    "    if abs(difference_ti) < 1: smooth_L1 = 0.5 * (difference_ti * difference_ti)\n",
    "    else : smooth_L1 = abs(difference_ti) - 0.5\n",
    "\n",
    "    return smooth_L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss_Regression. Lreg에 해당\n",
    "def Loss_Regression(predict_box, anchor_box, groundTruth_box) : \n",
    "    groundTruth_box = np.array([(groundTruth_box[2] + groundTruth_box[0])/2, (groundTruth_box[1] + groundTruth_box[3])/2, groundTruth_box[2] - groundTruth_box[0], groundTruth_box[3] - groundTruth_box[1]])\n",
    "\n",
    "    t_x = (predict_box[0] - anchor_box[0])/anchor_box[2]\n",
    "    t_y = (predict_box[1] - anchor_box[1])/anchor_box[3]\n",
    "    t_w = math.log10(predict_box[2]/anchor_box[2])\n",
    "    t_h = math.log10(predict_box[3]/anchor_box[3])\n",
    "\n",
    "\n",
    "    t_x_star = (groundTruth_box[0] - anchor_box[0])/anchor_box[2]\n",
    "    t_y_star = (groundTruth_box[1] - anchor_box[1])/anchor_box[3]\n",
    "    t_w_star = math.log10(groundTruth_box[2]/anchor_box[2])\n",
    "    t_h_star = math.log10(groundTruth_box[3]/anchor_box[3])\n",
    "\n",
    "    # Smooth L1 구하기\n",
    "    # 구성요소가 4개니까 4번 구해야겠지?\n",
    "    smooth_L1_x = Smooth_L1(t_x, t_x_star)\n",
    "    smooth_L1_y = Smooth_L1(t_y, t_y_star)\n",
    "    smooth_L1_w = Smooth_L1(t_w, t_w_star)\n",
    "    smooth_L1_h = Smooth_L1(t_h, t_h_star)\n",
    "\n",
    "    smooth_L1_list = smooth_L1_x + smooth_L1_y + smooth_L1_w + smooth_L1_h\n",
    "\n",
    "    return smooth_L1_list # 모아서 반환\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L_cls\n",
    "def Loss_Classes(cls_layer_output, pi_ground_truth) :\n",
    "    log_loss = -pi_ground_truth * math.log10(cls_layer_output[0]) - (1-pi_ground_truth)*math.log10(1-cls_layer_output[0])\n",
    "    return log_loss"
   ]
  },
  {
   "source": [
    "### 생각나는거\n",
    "### 테스트할 때 RPN에서 나온 RoI들을 Object score 기준으로 나열한 다음 상위 몇개만 걸러낸다(NMS)\n",
    "### 즉, 스코어를 뽑아낼 수 있는 방향으로 RPN의 Loss를 만들어야한다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss함수 수행. RPN의 출력값, 입력 이미지의 라벨값, 앵커를 받는다.\n",
    "def Loss_RPN(cls_layer_output, reg_layer_output, anchors, valid_anchor_bool, Ground_Truth_Box_list):\n",
    "    \n",
    "    # 앵커 선별\n",
    "    valid_anchor_bool, index_ground_truth_box_list = align_anchor(anchors, valid_anchor_bool, Ground_Truth_Box_list) # pos, neg 앵커 표시 + 모든 앵커에 대한 ground_truth_box_list\n",
    "    anchors_forMiniBatch, index_ground_truth_box_list_forMiniBatch, output_index_forMiniBatch, max_for = Create_Minibatch(anchors, index_ground_truth_box_list, valid_anchor_bool)\n",
    "    # output 선별 \n",
    "    cls_layer_output_forMiniBatch, reg_layer_output_forMiniBatch = get_output_anchor_forLoss(cls_layer_output, reg_layer_output, output_index_forMiniBatch)\n",
    "\n",
    "    # 자, 여기서 잠깐 생각을 해보자\n",
    "    # k = 9로 했으니 cls_layer의 결과값은 18개, reg_layer의 결과값은 36개가 있다. \n",
    "    # 앵커를 256개 랜덤해서 뽑겠다는 말이니까 결과값도 256쌍을 뽑아야한다. 그렇지? 이 256쌍은 뽑힌 앵커에 해당하는 출력값을 뽑아야한다. \n",
    "\n",
    "    N_cls = len(anchors_forMiniBatch)\n",
    "    N_reg = 14*14 # VGG 특성맵 최종 output 넓이. \n",
    "    lambda_forLoss = 10\n",
    "\n",
    "    Lcls_sum = 0\n",
    "    Lreg_sum = 0\n",
    "\n",
    "    # RPN의 cls output이 pi, reg  output이 ti이다.\n",
    "    # k = 9일 때 pi는 18개, ti는 36개라는 말.\n",
    "    for i in range(0, len(anchors_forMiniBatch)) :\n",
    "        pi_ground_truth = 0\n",
    "        if i < max_for : # Positive Anchor\n",
    "            pi_ground_truth = 1\n",
    "        #Lcls(classes loss)\n",
    "        Lcls_sum = Lcls_sum + Loss_Classes(cls_layer_output_forMiniBatch[i], pi_ground_truth)\n",
    "\n",
    "        #Lreg(regression loss)\n",
    "        if i < max_for : \n",
    "            index = int(index_ground_truth_box_list_forMiniBatch[i])\n",
    "            Ground_Truth_Box = Ground_Truth_Box_list[index]\n",
    "            Lreg_sum = Lreg_sum + Loss_Regression(reg_layer_output_forMiniBatch[i], anchors_forMiniBatch[i], Ground_Truth_Box)\n",
    "\n",
    "    loss = (1/N_cls) * Lcls_sum + lambda_forLoss*(1/N_reg)*Lreg_sum\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "source": [
    "## Fast-RCNN 부분(RoIPooling 등)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## 훈련을 위한 함수"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력용 이미지 생성. 224, 224로 변환시키고 채널 값(0~255)를 0~1 사이의 값으로 정규화 시켜줌\n",
    "def make_input(image_file_list): \n",
    "    images_list = []\n",
    "    \n",
    "    for i in tqdm(range(0, len(image_file_list))) :\n",
    "        \n",
    "        image = cv2.imread(image_file_list[i])\n",
    "        image = cv2.resize(image, (224, 224))/255\n",
    "        \n",
    "        images_list.append(image)\n",
    "    \n",
    "    return np.asarray(images_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output_RPN(image, SharedConvNet, RPN_intermediate_layer, RPN_cls_Layer, RPN_reg_Layer):\n",
    "    Conv_FeatureMap = SharedConvNet(np.expand_dims(image, axis=0))\n",
    "    RPN_intermedi = RPN_intermediate_layer(Conv_FeatureMap)\n",
    "\n",
    "    cls_layer_output = RPN_cls_Layer(RPN_intermedi)[0] # 14*14*18\n",
    "    reg_layer_output = RPN_reg_Layer(RPN_intermedi)[0] # 14*14*36\n",
    "\n",
    "    cls_layer_output_forUse = []\n",
    "    reg_layer_output_forUse = []\n",
    "\n",
    "    anchor_size = [32, 64, 128] # 이미지 크기가 224*224라 32, 64, 128로 지정\n",
    "    anchor_aspect_ratio = [[1,1],[1,0.5], [0.5,1]] # W*L기준 \n",
    "\n",
    "    for y in range(0, 14):\n",
    "        for x in range(0, 14):\n",
    "                for i in range(0, len(anchor_size)):\n",
    "                    for j in range(0, len(anchor_aspect_ratio)):\n",
    "                        score = [cls_layer_output[y][x][2*(3*i+j)], cls_layer_output[y][x][2*(3*i+j) + 1]] # 오브젝트다 vs 아니다 2개 항목에 대한 스코어 저장(각 앵커당)\n",
    "                        cls_layer_output_forUse.append(tf.nn.softmax(score))\n",
    "                        \n",
    "                        center_x = 8 + 16 * x \n",
    "                        center_y = 8 + 16 * y\n",
    "                        w = anchor_size[i] * anchor_aspect_ratio[j][0]\n",
    "                        h = anchor_size[i] * anchor_aspect_ratio[j][1]\n",
    "\n",
    "                        score_x = center_x + reg_layer_output[y][x][4*(3*i+j)]\n",
    "                        score_y = center_y + reg_layer_output[y][x][4*(3*i+j) + 1]\n",
    "                        score_w = w + reg_layer_output[y][x][4*(3*i+j) + 2]\n",
    "                        score_h = h + reg_layer_output[y][x][4*(3*i+j) + 3]\n",
    "\n",
    "                        box_info = [score_x, score_y, score_w, score_h]\n",
    "                        reg_layer_output_forUse.append(box_info)\n",
    "\n",
    "    return np.array(cls_layer_output_forUse), np.array(reg_layer_output_forUse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_RPN(input_image, xml_file, Classes_inDataSet, SharedConvNet, RPN_intermediate_layer, RPN_cls_Layer, RPN_reg_Layer, anchors, valid_anchor_bool, lr):\n",
    "    Classes_inImage, Ground_Truth_Box_list = get_label_fromImage(xml_file, Classes_inDataSet) # label 휙득\n",
    "    cls_layer_output_forUse, reg_layer_output_forUse = get_output_RPN(input_image, SharedConvNet, RPN_intermediate_layer, RPN_cls_Layer, RPN_reg_Layer) # output 구하기\n",
    "    loss = Loss_RPN(cls_layer_output_forUse, reg_layer_output_forUse, anchors, valid_anchor_bool, Ground_Truth_Box_list)\n",
    "\n",
    "    # loss를 구했는데 어떻게 훈련시키냐 아 ㅋㅋ\n",
    "    momentum = 0.9\n",
    "    weight_decay = 0.0005\n"
   ]
  },
  {
   "source": [
    "### RPN 흐름 정리(훈련)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 리스트\n",
    "image_file_list = sorted([x for x in glob.glob(train_x_path + '/**')])\n",
    "xml_file_list = sorted([x for x in glob.glob(train_y_path + '/**')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 5011/5011 [00:17<00:00, 286.51it/s]\n"
     ]
    }
   ],
   "source": [
    "# 입력 이미지 생성\n",
    "input_image_list = make_input(image_file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 존재하는 객체 종류를 알아내자\n",
    "def get_Classes_inImage(xml_file_list):\n",
    "    classes = []\n",
    "\n",
    "    for xml_file_path in xml_file_list: \n",
    "\n",
    "        f = open(xml_file_path)\n",
    "        xml_file = xmltodict.parse(f.read())\n",
    "        # 사진에 객체가 여러개 있을 경우\n",
    "        try: \n",
    "            for obj in xml_file['annotation']['object']:\n",
    "                classes.append(obj['name'].lower()) # 들어있는 객체 종류를 알아낸다\n",
    "        # 사진에 객체가 하나만 있을 경우\n",
    "        except TypeError as e: \n",
    "            classes.append(xml_file['annotation']['object']['name'].lower()) \n",
    "        f.close()\n",
    "\n",
    "    classes = list(set(classes)) # set은 중복된걸 다 제거하고 유니크한? 아무튼 하나만 가져온다. 그걸 리스트로 만든다\n",
    "    classes.sort() # 정렬\n",
    "\n",
    "    return classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Classes_inDataSet = get_Classes_inImage(xml_file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_num = len(tf.keras.applications.VGG16(weights='imagenet', include_top=False,  input_shape=(224, 224, 3)).layers) # 레이어 최대 개수\n",
    "\n",
    "SharedConvNet = tf.keras.models.Sequential()\n",
    "for i in range(0, max_num-1):\n",
    "    SharedConvNet.add(tf.keras.applications.VGG16(weights='imagenet', include_top=False,  input_shape=(224, 224, 3)).layers[i])\n",
    "\n",
    "initializer = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.01, seed=None)\n",
    "\n",
    "RPN_intermediate_layer = tf.keras.layers.Conv2D(512, (3,3), kernel_initializer = initializer, activation='relu', padding='SAME', input_shape=(14, 14, 512))\n",
    "RPN_cls_Layer = tf.keras.layers.Conv2D(18, (1,1), kernel_initializer = initializer, input_shape=(14, 14, 512)) # 클래스인가? 아닌가? \n",
    "RPN_reg_Layer = tf.keras.layers.Conv2D(36, (1,1), kernel_initializer = initializer, input_shape=(14, 14, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = (RPN_cls_Layer.weights[0][0][0][511][17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=1.9944729>"
      ]
     },
     "metadata": {},
     "execution_count": 157
    }
   ],
   "source": [
    "test + 2 # 가중치를 일일이 다 불러와서 경사하강법 적용하면 되겠다 ^오^\n",
    "# 가중치 불러오기 -> 업데이트 -> 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[<tf.Variable 'conv2d_1/kernel:0' shape=(1, 1, 512, 18) dtype=float32, numpy=\narray([[[[ 0.00153891, -0.00039054, -0.00392993, ..., -0.00724896,\n           0.00945011,  0.00443572],\n         [-0.00159282,  0.00469282, -0.01365773, ..., -0.00591567,\n           0.00327307, -0.00834619],\n         [ 0.00762109,  0.017832  , -0.00866503, ..., -0.01427393,\n          -0.01806705,  0.00723966],\n         ...,\n         [-0.00191052,  0.01792054, -0.00434975, ...,  0.00578483,\n          -0.01136053,  0.0007477 ],\n         [ 0.01468072, -0.00609638,  0.00692405, ..., -0.01397917,\n           0.01846595,  0.01325233],\n         [ 0.00669655,  0.00203889,  0.0202539 , ...,  0.01167233,\n          -0.0087166 , -0.00552713]]]], dtype=float32)>, <tf.Variable 'conv2d_1/bias:0' shape=(18,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0.], dtype=float32)>, <tf.Variable 'conv2d_1/kernel:0' shape=(1, 1, 512, 18) dtype=float32, numpy=\narray([[[[ 0.00153891, -0.00039054, -0.00392993, ..., -0.00724896,\n           0.00945011,  0.00443572],\n         [-0.00159282,  0.00469282, -0.01365773, ..., -0.00591567,\n           0.00327307, -0.00834619],\n         [ 0.00762109,  0.017832  , -0.00866503, ..., -0.01427393,\n          -0.01806705,  0.00723966],\n         ...,\n         [-0.00191052,  0.01792054, -0.00434975, ...,  0.00578483,\n          -0.01136053,  0.0007477 ],\n         [ 0.01468072, -0.00609638,  0.00692405, ..., -0.01397917,\n           0.01846595,  0.01325233],\n         [ 0.00669655,  0.00203889,  0.0202539 , ...,  0.01167233,\n          -0.0087166 , -0.00552713]]]], dtype=float32)>, <tf.Variable 'conv2d_1/bias:0' shape=(18,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0.], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3 # 논문에서 n은 VGG16을 거치고 나온 특성맵 위를 슬라이딩 할 커널의 크기\n",
    "\n",
    "# 생성할 앵커 크기는? \n",
    "anchor_size = [32, 64, 128] # 이미지 크기가 224*224라 32, 64, 128로 지정\n",
    "anchor_aspect_ratio = [[1,1],[1,0.5], [0.5,1]] # W*L기준 \n",
    "anchors, valid_anchor_bool = make_anchor(anchor_size, anchor_aspect_ratio) # 앵커 생성 + 유효한 앵커 인덱스 휙득\n",
    "\n"
   ]
  }
 ]
}